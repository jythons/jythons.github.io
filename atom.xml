<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Jythons小站]]></title>
  <link href="jythons.github.io/atom.xml" rel="self"/>
  <link href="jythons.github.io/"/>
  <updated>2021-01-21T23:03:19+08:00</updated>
  <id>jythons.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.coderforart.com/">CoderForArt</generator>

  
  <entry>
    <title type="html"><![CDATA[ES查询 - 批量操作]]></title>
    <link href="jythons.github.io/16111534541333.html"/>
    <updated>2021-01-20T22:37:34+08:00</updated>
    <id>jythons.github.io/16111534541333.html</id>
    <content type="html"><![CDATA[
<p>使用id查询单条记录的方式，如果要查询n次，我们就要调用n次查询接口，这样做会对资源造成浪费，因此ES提供了批量查询的方法。<br/>
<span id="more"></span><!-- more --></p>

<h2 id="toc_0">1 批量查询：mget</h2>

<table>
<thead>
<tr>
<th>名称</th>
<th>数值</th>
<th>备注</th>
</tr>
</thead>

<tbody>
<tr>
<td>请求地址</td>
<td><a href="http://192.168.3.214:9200/shop/_mget">http://192.168.3.214:9200/shop/_mget</a></td>
<td></td>
</tr>
<tr>
<td>请求方式</td>
<td>POST</td>
<td></td>
</tr>
</tbody>
</table>

<p><strong>请求参数</strong></p>

<pre><code class="language-text">{
    &quot;ids&quot;:[&quot;1001&quot;, &quot;1003&quot;, &quot;1005&quot;]
}
</code></pre>

<blockquote>
<p>使用mget搜索不会像使用_search指定ID查询数据那样，展示源信息。<br/>
使用mget查询数据时，如果这个数据不存在，则，这个id对应的数据行也会查询出来，不过，这行数据的found字段对应的值是：false；使用_search查询，如果数据不存在，则不会展示那行数据。</p>
</blockquote>

<h2 id="toc_1">2 批量操作：_bulk</h2>

<h3 id="toc_2">2.1 基本语法</h3>

<p>bulk操作和以往的普通请求格式有区别，不要格式化json，不然就不在同一行了，这个需要注意。</p>

<pre><code class="language-text">{action: {metadata}}\n
{request body      }\n
{action: {meatdata}}\n
{request body      }\n
</code></pre>

<blockquote>
<p>{action: {metadata}} 代表批量操作的类型，可以是新增、删除或修改<br/>
\n是每行结尾必须填写的一个规范，每一行包括最后一行都要写，用于es的解析<br/>
{request body}是请求body，增加和修改操作需要，删除操作则不需要</p>
</blockquote>

<h3 id="toc_3">2.2 批量操作的类型</h3>

<p>action必须是以下选项之一：</p>

<ul>
<li>create: 如果文档不存在，那么久创建他，存在会报错。发生异常报错不会影响其他操作。</li>
<li>index: 创建一个新文档或者替换一个现有的文档。</li>
<li>update: 部分更新一个文档。</li>
<li>delete: 删除一个文档</li>
</ul>

<blockquote>
<p>metadata中需要指定要操作的文档的_index、type和_id，_index、_type也可以在url中指定。</p>
</blockquote>

<h3 id="toc_4">2.3 实际操作</h3>

<table>
<thead>
<tr>
<th>名称</th>
<th>数值</th>
<th>备注</th>
</tr>
</thead>

<tbody>
<tr>
<td>请求地址</td>
<td><a href="http://192.168.3.214:9200/_bulk">http://192.168.3.214:9200/_bulk</a></td>
<td></td>
</tr>
<tr>
<td>请求方式</td>
<td>POST</td>
<td></td>
</tr>
</tbody>
</table>

<h4 id="toc_5">2.3.1 批量创建：create</h4>

<pre><code class="language-text">{&quot;create&quot;: {&quot;_index&quot;: &quot;shop&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;2001&quot;}}
{&quot;id&quot;: &quot;2001&quot;, &quot;nickname&quot;: &quot;name-2001&quot;}
{&quot;create&quot;: {&quot;_index&quot;: &quot;shop&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;2002&quot;}}
{&quot;id&quot;: &quot;2002&quot;, &quot;nickname&quot;: &quot;name-2002&quot;}
{&quot;create&quot;: {&quot;_index&quot;: &quot;shop&quot;, &quot;_type&quot;: &quot;_doc&quot;, &quot;_id&quot;: &quot;2003&quot;}}
{&quot;id&quot;: &quot;2003&quot;, &quot;nickname&quot;: &quot;name-2003&quot;}

</code></pre>

<blockquote>
<p>创建文档时，如果文档不存在，则他会创建，如果这个文档存在，则他会报一个异常，不过这个异常不会影响其他的批量操作。上面的参数中，索引和类型可以写到URL上面，不必再参数中每一个文档都写一遍：<a href="http://192.168.3.214:9200/shop/_doc/_bulk%E3%80%82">http://192.168.3.214:9200/shop/_doc/_bulk。</a></p>
</blockquote>

<h4 id="toc_6">2.3.2 批量创建：index</h4>

<p>上面的create在创建时，如果文档存在，则会抛出异常，如果我们想在文档存在时更新这个文档的话，可以使用：index。</p>

<pre><code class="language-text">{&quot;index&quot;: {&quot;_id&quot;: &quot;2001&quot;}}
{&quot;id&quot;: &quot;2001&quot;, &quot;nickname&quot;: &quot;name-2001&quot;}
{&quot;index&quot;: {&quot;_id&quot;: &quot;2002&quot;}}
{&quot;id&quot;: &quot;2002&quot;, &quot;nickname&quot;: &quot;name-2002&quot;}
{&quot;index&quot;: {&quot;_id&quot;: &quot;2003&quot;}}
{&quot;id&quot;: &quot;2003&quot;, &quot;nickname&quot;: &quot;name-2003&quot;}

</code></pre>

<h4 id="toc_7">2.3.3 批量更新：update</h4>

<pre><code class="language-text">{&quot;update&quot;: {&quot;_id&quot;: &quot;2001&quot;}}
{&quot;doc&quot;: {&quot;id&quot;: &quot;2001&quot;}}
{&quot;update&quot;: {&quot;_id&quot;: &quot;2002&quot;}}
{&quot;doc&quot;: {&quot;nickname&quot;: &quot;name-2002&quot;}}

</code></pre>

<blockquote>
<p>批量更新可以局部更新，参数中只需要填写想要更新的文档内的某个字段。</p>
</blockquote>

<h4 id="toc_8">2.3.4 批量删除：delete</h4>

<pre><code class="language-text">{&quot;delete&quot;: {&quot;_id&quot;: &quot;2001&quot;}}
{&quot;delete&quot;: {&quot;_id&quot;: &quot;2002&quot;}}

</code></pre>

<h2 id="toc_9">总结</h2>

<p>上面的CURD的操作可以混合在一起使用，同一个请求参数可以混合所有的操作。 <br/>
整个批量请求都需要由接收到请求的节点加载到内存中，因此该请求越大，其他请求所能获得的内存就越少。 批量请求的大小有一个最佳值，大于这个值，性能将不再提升，甚至会下降。 但是最佳值不是一个固定的值。它完全取决于硬件、文档的大小和复杂度、索引和搜索的负载的整体情况。<br/>
幸运的是，很容易找到这个 最佳点 ：通过批量索引典型文档，并不断增加批量大小进行尝试。 当性能开始下降，那么你的批量大小就太大了。一个好的办法是开始时将 1,000 到 5,000 个文档作为一个批次, 如果你的文档非常大，那么就减少批量的文档个数。<br/>
密切关注你的批量请求的物理大小往往非常有用，一千个 1KB 的文档是完全不同于一千个 1MB 文档所占的物理大小。 一个好的批量大小在开始处理后所占用的物理大小约为 5-15 MB。</p>

<p><a href="https://www.elastic.co/guide/cn/elasticsearch/guide/current/bulk.html">官方文档</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ES 深度分页]]></title>
    <link href="jythons.github.io/16111512182369.html"/>
    <updated>2021-01-20T22:00:18+08:00</updated>
    <id>jythons.github.io/16111512182369.html</id>
    <content type="html"><![CDATA[
<p>正常的使用from和size去分页查询的时候，from+size的结果要小于10000，因为ES内部考虑到性能的因素，对此做了限制。<br/>
ES在查询数据的时候，例如获取9999-10009的数据时，他的from=9999，size=10，假如有3个shard，每个shard有10W条数据，他会从每个shard获取10009条数据，合成一个结果集，在从这个结果集中取10条数据，剩下的30017条数据就会丢弃，这么做的缺点会造成资源和性能的浪费。<br/>
<span id="more"></span><!-- more --><br/>
<img src="media/16111512182369/ES%E6%B7%B1%E5%BA%A6%E5%88%86%E9%A1%B5.png" alt="ES深度分页"/></p>

<blockquote>
<p>针对上述问题，可以使用限制总页数的方式去规避，查询大于10000条数据的问题，例如，查询页数，限制在最大100页。</p>
</blockquote>

<h2 id="toc_0">突破10000条数据的限制</h2>

<p>如果在某些企业内部，对查询数据有特殊的要求，对于性能没有必要的要求的话，可以通过修改配置来突破10000数据的查询限制。</p>

<h3 id="toc_1">查询配置信息的方法</h3>

<table>
<thead>
<tr>
<th>名称</th>
<th>数值</th>
<th>备注</th>
</tr>
</thead>

<tbody>
<tr>
<td>请求地址</td>
<td><a href="http://192.168.3.214:9200/shop/_settings">http://192.168.3.214:9200/shop/_settings</a></td>
<td></td>
</tr>
<tr>
<td>请求类型</td>
<td>GET</td>
<td></td>
</tr>
</tbody>
</table>

<h3 id="toc_2">修改配置</h3>

<table>
<thead>
<tr>
<th>名称</th>
<th>数值</th>
<th>备注</th>
</tr>
</thead>

<tbody>
<tr>
<td>请求地址</td>
<td><a href="http://192.168.3.214:9200/shop/_settings">http://192.168.3.214:9200/shop/_settings</a></td>
<td>shop:索引</td>
</tr>
<tr>
<td>请求方式</td>
<td>put</td>
<td></td>
</tr>
<tr>
<td>参数类型</td>
<td>json</td>
<td></td>
</tr>
<tr>
<td>请求参数</td>
<td>见下方请求参数</td>
<td></td>
</tr>
<tr>
<td>响应类型</td>
<td>json</td>
<td></td>
</tr>
<tr>
<td>响应数据</td>
<td>见下方响应数据</td>
<td></td>
</tr>
</tbody>
</table>

<p><strong>请求参数</strong></p>

<pre><code class="language-text">{
    &quot;index.max_result_windows&quot;: 100000
}
</code></pre>

<p><strong>响应数据</strong></p>

<pre><code class="language-text">{
    &quot;acknowledged&quot;: true
}
</code></pre>

<h2 id="toc_3">Scroll 滚动搜索</h2>

<p>上面通过对配置的修改来获取大数据量的搜索，对性能上是有影响，实际生产上是不推荐这么做的，我们还可以通过使用scroll滚动搜索的方式来查询大数据量的搜索工作。</p>

<h3 id="toc_4">滚动搜索原理</h3>

<p>可以把 scroll 理解爲关系型数据库里的 cursor，因此，scroll 并不适合用来做实时搜索，而更适用于后台批处理任务，比如群发。<br/>
scroll 具体分为初始化和遍历两步，初始化时将所有符合搜索条件的搜索结果缓存起来，可以想象成快照，在遍历时，从这个快照里取数据，也就是说，在初始化后对索引插入、删除、更新数据都不会影响遍历结果。游标可以增加性能的原因，是因为如果做深分页，每次搜索都必须重新排序，非常浪费，使用scroll就是一次把要用的数据都排完了，分批取出，因此比使用from+size还好。</p>

<h3 id="toc_5">搜索示例</h3>

<table>
<thead>
<tr>
<th>名称</th>
<th>数值</th>
<th>备注</th>
</tr>
</thead>

<tbody>
<tr>
<td>请求地址</td>
<td><a href="http://192.168.3.214:9200/shop/_search?scroll=1m">http://192.168.3.214:9200/shop/_search?scroll=1m</a></td>
<td>scroll表示滚动时间，也就是说缓存起来的数据的有效期，这里设置的是1分钟。</td>
</tr>
<tr>
<td>请求类型</td>
<td>POST</td>
<td></td>
</tr>
<tr>
<td>请求参数</td>
<td>见下方请求参数</td>
<td></td>
</tr>
</tbody>
</table>

<p><strong>请求参数</strong></p>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;match_all&quot;: {}
    },
    &quot;sort&quot;: [&quot;_doc&quot;],
    &quot;size&quot;: 5   # 每次滚动的数据数量
}
</code></pre>

<blockquote>
<p>第一次查询会返回一个scroll_id，在第二次滚动查询时，需要带上这个scroll_id。</p>
</blockquote>

<p><strong>第二次滚动搜索</strong></p>

<table>
<thead>
<tr>
<th>名称</th>
<th>数值</th>
<th>备注</th>
</tr>
</thead>

<tbody>
<tr>
<td>请求地址</td>
<td><a href="http://192.168.3.214:9200/_search/scroll">http://192.168.3.214:9200/_search/scroll</a></td>
<td></td>
</tr>
<tr>
<td>请求类型</td>
<td>POST</td>
<td></td>
</tr>
</tbody>
</table>

<pre><code class="language-text">{
    &quot;scroll_id&quot;: &quot;SGsguighdasdhkHSkhdashkd==&quot;,
    &quot;scroll&quot;: &quot;1m&quot;
}
</code></pre>

<blockquote>
<p>每一次滚动查询，都要将上一次查询的scroll_id携带过来，直到查询得结果集为空。 <br/>
上面设置的size是作用于单个分片，所以如果有多个分片的话，每次实际返回的文档数量最大为：size * 分片数量</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ES dsl搜索]]></title>
    <link href="jythons.github.io/16105497801984.html"/>
    <updated>2021-01-13T22:56:20+08:00</updated>
    <id>jythons.github.io/16105497801984.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<h2 id="toc_0">QueryString的方式查询数据</h2>

<table>
<thead>
<tr>
<th>名称</th>
<th>值</th>
<th>备注</th>
</tr>
</thead>

<tbody>
<tr>
<td>请求方式</td>
<td>GET</td>
<td></td>
</tr>
<tr>
<td>请求地址</td>
<td><a href="http://192.168.3.214:9200/index/_search?q=desc:%E4%BD%A0%E5%A5%BD">http://192.168.3.214:9200/index/_search?q=desc:你好</a></td>
<td></td>
</tr>
<tr>
<td>解析</td>
<td>index</td>
<td>索引名称</td>
</tr>
<tr>
<td></td>
<td>_search</td>
<td>表示搜索</td>
</tr>
<tr>
<td></td>
<td>q=desc:你好</td>
<td>表示查询desc这个字段里面包含你好的数据</td>
</tr>
</tbody>
</table>

<blockquote>
<p>多个查询条件可以在q后面再加一个q=age:22.<br/>
例如：?q=desc:你好&amp;q=age:22</p>
</blockquote>

<h2 id="toc_1">DSL的方式查询数据</h2>

<blockquote>
<p>QueryString的方式查询数据不够灵活，不适用复杂查询。<br/>
使用DSL的方式查询更加灵活、方便、支持复杂查询。</p>
</blockquote>

<h3 id="toc_2">使用DSL查询数据方法</h3>

<table>
<thead>
<tr>
<th>名称</th>
<th>值</th>
<th>备注</th>
</tr>
</thead>

<tbody>
<tr>
<td>请求方式</td>
<td>POST</td>
<td></td>
</tr>
<tr>
<td>请求地址</td>
<td><a href="http://192.168.3.214:9200/index/_doc/_search">http://192.168.3.214:9200/index/_doc/_search</a></td>
<td></td>
</tr>
<tr>
<td>参数类型</td>
<td>JSON</td>
<td>参数格式见下表</td>
</tr>
</tbody>
</table>

<h4 id="toc_3">根据字段内容查询数据</h4>

<blockquote>
<p>根据字段查询数据，如果该字段不支持分词，例如keyword类型的字段，查询的字段内容只是一部分的话，是查不出来数据的。</p>
</blockquote>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;match&quot;: {
            &quot;desc&quot;: &quot;你好&quot;
        }
    }
}
</code></pre>

<p>如果要查询同时满足两个词汇都存在的数据，可以使用下面这种方式查询：</p>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;match&quot;: {
            &quot;desc&quot;: {
                &quot;query&quot;: &quot;你好 学习&quot;,
                &quot;operator&quot;:&quot;and&quot; # 表示要同时满足查询的所有词汇，默认是or，相当于上面的方式查询
            }
        }
    }
}
</code></pre>

<p>minimum_should_match, 这个属性表示查询的字符串被分词后，匹配百分之多少词汇的数据。例如查询：今天天气好晴朗，我想出去玩。假设这个句子被分成10个词汇，minimum_should_match参数设置60%（向下取整 ），表示查询的数据中，匹配上6个词汇就会被查询出来。</p>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;match&quot;: {
            &quot;desc&quot;: {
                &quot;query&quot;: &quot;今天天气好晴朗，我想出去玩&quot;,
                &quot;minimum_should_match&quot;: &quot;60%&quot; 
            }
        }
    }
}
</code></pre>

<h4 id="toc_4">查询索引是否包含某个属性</h4>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;exists&quot;: {
            &quot;field&quot;: &quot;username&quot;
        }
    }
}
</code></pre>

<h4 id="toc_5">查询所有</h4>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;match_all&quot;: {}
    }
}
</code></pre>

<h4 id="toc_6">查询部分字段数据</h4>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;match_all&quot;: {}
    },
    &quot;_source&quot;: [
        &quot;id&quot;,
        &quot;nickname&quot;,
        &quot;age&quot;
    ]
}
</code></pre>

<h4 id="toc_7">分页查询</h4>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;match_all&quot;: {}
    },
    &quot;_source&quot;: [
        &quot;id&quot;,
        &quot;nickname&quot;,
        &quot;age&quot;
    ],
    &quot;from&quot;: 0, # 数据起始位置
    &quot;size&quot;: 10 # 每页展示数量
}
</code></pre>

<h4 id="toc_8">根据字段内容模糊匹配</h4>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;term&quot;: {
            &quot;desc&quot;: &quot;你好&quot;
        }
    },
    &quot;_source&quot;: [
        &quot;id&quot;,
        &quot;nickname&quot;,
        &quot;desc&quot;
    ]
}
</code></pre>

<blockquote>
<p>term 是模糊搜索这个字段内容，只要这个字段内容包含搜索的字符串，就展示出来，match是分词搜索，首先会对搜索的字符串进行分词，然后会检索出所有包含这些分词的数据。</p>
</blockquote>

<p>也可以同时查询多个词汇：</p>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;terms&quot;: {
            &quot;desc&quot;: [&quot;你好&quot;, &quot;学习&quot;]
        }
    },
    &quot;_source&quot;: [
        &quot;id&quot;,
        &quot;nickname&quot;,
        &quot;desc&quot;
    ]
}
</code></pre>

<blockquote>
<p>使用terms是可以支持多个词汇查询，只要包含搜索词汇中的其中一个，就会被检索出来。</p>
</blockquote>

<h4 id="toc_9">根据词条去查询</h4>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;match_phrase&quot;: {
            &quot;desc&quot;: {
                &quot;query&quot;: &quot;大学 毕业&quot;
            }
        }
    },
    &quot;_source&quot;: [
        &quot;id&quot;,
        &quot;nickname&quot;,
        &quot;desc&quot;
    ]
}

</code></pre>

<blockquote>
<p>使用match_phrase查询，首先会对查询的词条进行分词，然后去找这些分词同时在这个字段内容下的数据。上面的例子两个词汇，需要连贯在一起才能查询出来。如果要查询非连贯的词汇，可以使用下面的方式。</p>
</blockquote>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;match_phrase&quot;: {
            &quot;desc&quot;: {
                &quot;query&quot;: &quot;大学 毕业&quot;,
                &quot;slop&quot;: 3 # 这个参数表示大学和毕业中间可以跳过多少个词汇
            }
        }
    },
    &quot;_source&quot;: [
        &quot;id&quot;,
        &quot;nickname&quot;,
        &quot;desc&quot;
    ]
}

</code></pre>

<h4 id="toc_10">指定多个ID查询</h4>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;ids&quot;: {
            &quot;type&quot;: &quot;_doc&quot;,
            &quot;values&quot;: [&quot;1001&quot;, &quot;1002&quot;, &quot;1009&quot;]
        }
    },
    &quot;_source&quot;: [
        &quot;id&quot;,
        &quot;nickname&quot;,
        &quot;desc&quot;
    ]
}
</code></pre>

<h4 id="toc_11">在多个字段去查询</h4>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;multi_match&quot;: {
            &quot;desc&quot;: &quot;你好啊&quot;,
            &quot;fields&quot;: [
                &quot;desc&quot;, &quot;nickname^10&quot;
            ]
        }
    }
}
</code></pre>

<blockquote>
<p>由于默认匹配的词汇越少，分数越低，搜索出来的数据排名会靠下，如果要对某个字段查询出来的数据提升排名，则可以为这个字段设置权重，设置方法见上方：&quot;nickname ^ 10&quot;</p>
</blockquote>

<h4 id="toc_12">布尔查询</h4>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;bool&quot;: {
            &quot;must&quot;: [
                {
                    &quot;multi_match&quot;: {
                        &quot;query&quot;: &quot;你好&quot;,
                        &quot;fields&quot;: [&quot;desc&quot;, &quot;nickname&quot;]
                    }
                },{
                    &quot;term&quot;: {
                        &quot;sex&quot;: 0
                    }
                }
            ],
            &quot;should&quot;: [
                {
                    &quot;match&quot;: {
                       &quot;desc&quot;: &quot;我 &quot;
                    }
                }
            ]
        }
    }
}
</code></pre>

<blockquote>
<p>must: 表示同时满足对应的词汇才会被搜索出来（相当于mysql的AND）<br/>
must_not: 表示所有词汇都不满足才会被搜索出来 (相当于MySQL的not)<br/>
should: 表示所有词汇只要满足一个就会被搜索出来（相当于MySQL的or）</p>
</blockquote>

<p>有时候我们想把分数较低的词汇排名靠前，可以是boost属性为这个词汇加权，使用方法见下方示例:</p>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;bool&quot;: {
            &quot;should&quot;: [
                {
                    &quot;match&quot;: {
                        &quot;query&quot;: &quot;你好&quot;,
                        &quot;boost&quot;: 2
                    }
                },{
                    &quot;match&quot;: {
                        &quot;query&quot;: &quot;律师&quot;,
                        &quot;boost&quot;: 10
                    }
                }
            ]
        }
    }
}
</code></pre>

<h4 id="toc_13">过滤器</h4>

<p>过滤器，顾名思义可以在数据集合中过滤出自己想要的数据，比如过滤数据中金额在50~60之间的数据。</p>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;match&quot;: {
            &quot;desc&quot;: &quot;五子棋游戏&quot;
        }
    },
    &quot;post_filter&quot;: {
        &quot;range&quot;: {
            &quot;money&quot;: {
                &quot;gt&quot;: 50,
                &quot;lt&quot;: 60
            }
        }
    }
}
</code></pre>

<blockquote>
<p>上面参数中，post_filter表示过滤的意思，与query平级；range表示范围查询，money是mapping的一个字段。<br/>
gt：大于，lt：小于，gte：大于等于，lte：小于等于</p>
</blockquote>

<h4 id="toc_14">排序</h4>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;match&quot;: {
            &quot;desc&quot;: &quot;五子棋游戏&quot;
        }
    },
    &quot;sort&quot;: [
        {
            &quot;age&quot;: &quot;desc&quot;
        }
    ]
}
</code></pre>

<blockquote>
<p>支持分词的字段，是不能进行排序的，比如text类型的字段，如果要对这个字段进行排序，可以为这个字段添加一个附属的属性用于排序，可以参考下面创建mapping的例子：</p>
</blockquote>

<pre><code class="language-text">{
    &quot;properties&quot;: {
        &quot;id&quot;: {
            &quot;type&quot;: &quot;long&quot;
        },
        &quot;nickname&quot;: {
            &quot;type&quot;: &quot;text&quot;,
            &quot;analyzer&quot;: &quot;ik_max_word&quot;,
            &quot;fields&quot;: {
                &quot;keyword&quot;: { # 这里的keyword，如果下面有text类型的字段需要排序也可以取相同的名字
                    &quot;type&quot;: &quot;keyword&quot;
                }
            }
        }
    }
}
</code></pre>

<p>创建好可以排序的text类型的字段后，在使用这个字段排序时，需要使用如下方式去排序：</p>

<pre><code class="language-text">{
    &quot;sort&quot;: [
        {
            &quot;nickname.keyword&quot;: &quot;desc&quot;
        }
    ]
}
</code></pre>

<blockquote>
<p>这里的nickname是字段名称，keyword是这个字段的附属属性的名称。</p>
</blockquote>

<h4 id="toc_15">搜索出的数据中匹配的词汇高亮</h4>

<p>在我们搜索出来的数据，是根据查询的字符串分词后的词汇匹配出来的，我们可以将这些词汇进行高亮显示。<br/>
使用高亮显示的方式如下:</p>

<pre><code class="language-text">{
    &quot;query&quot;: {
        &quot;match&quot;: {
            &quot;desc&quot;: &quot;五子棋游戏&quot;
        }
    },
    &quot;highlight&quot;: { # 高亮显示配置
        &quot;pre_tags&quot;: [&quot;&lt;span&gt;&quot;],   # 高亮显示的词汇前置标签
        &quot;post_tags&quot;: [&quot;&lt;/span&gt;&quot;], # 高亮显示的词汇结束标签
        &quot;fields&quot;: {
            &quot;desc&quot;: {}  # 高亮显示的字段
        }
    }
}
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ES 分词与内置分词器]]></title>
    <link href="jythons.github.io/16103794709126.html"/>
    <updated>2021-01-11T23:37:50+08:00</updated>
    <id>jythons.github.io/16103794709126.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>分词就是将一段文字进行切分，将里面的词汇提取出来，这个过程就是分词。<br/>
ES 本身不支持中文的分词</p>
</blockquote>

<span id="more"></span><!-- more -->

<h2 id="toc_0">分词的简单使用</h2>

<table>
<thead>
<tr>
<th>请求方式</th>
<th>POST</th>
</tr>
</thead>

<tbody>
<tr>
<td>请求地址</td>
<td><a href="http://192.168.3.214:9200/_analyze">http://192.168.3.214:9200/_analyze</a></td>
</tr>
<tr>
<td>请求地址</td>
<td><a href="http://192.168.3.214:9200/my_doc/_analyze">http://192.168.3.214:9200/my_doc/_analyze</a></td>
</tr>
<tr>
<td>请求body</td>
<td>见下方代码</td>
</tr>
</tbody>
</table>

<pre><code class="language-text">{
    &quot;analyzer&quot; : &quot;standard&quot;,
    &quot;text&quot;: &quot;I study ES&quot;
}
</code></pre>

<blockquote>
<p>默认的分词器在解析中文的时候，会将中文的每一个汉字提取出来。如果要解析中文，需要使用中文分词器。</p>
</blockquote>

<h2 id="toc_1">分词器类型</h2>

<table>
<thead>
<tr>
<th>分词器</th>
<th>名称</th>
<th>备注</th>
</tr>
</thead>

<tbody>
<tr>
<td>standard</td>
<td>默认分词器，单词会被拆分</td>
<td>大写字母会被转换为小写</td>
</tr>
<tr>
<td>whitespace</td>
<td>按照空格分词，忽略大小写</td>
<td>会保留大写字母</td>
</tr>
<tr>
<td>stop</td>
<td>去除无意义的单词</td>
<td>例如：a、the等助词会被去除</td>
</tr>
<tr>
<td>keyword</td>
<td>不做分词，把整个文本作为一个单独的关键词</td>
<td></td>
</tr>
<tr>
<td>simple</td>
<td>按照非字母分词，大写转为小写</td>
<td></td>
</tr>
</tbody>
</table>

<h2 id="toc_2">建立ik中文分词器</h2>

<blockquote>
<p>上面的分词器都不支持中文，如果要对中文进行分词，我们就要用到一个开源的中文分词器: ik分词器。</p>
</blockquote>

<p>源码地址：<a href="https://github.com/medcl/elasticsearch-analysis-ik">ik分词器</a></p>

<h3 id="toc_3">ik分词器安装</h3>

<p>将下载好的包解压到ES目录下的plugins目录下</p>

<pre><code class="language-text">tar -zxvf elasticsearch-analysis-ik-7.10.1.zip -d /usr/local/es/plugins/ik
</code></pre>

<p>然后重新启动ES即可。 </p>

<h3 id="toc_4">ik分词器（来自GitHub说明）</h3>

<p>ik分词器有以下两种：ik_max_word和ik_smart<br/>
ik_max_word: 会将文本做最细粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,中华人民,中华,华人,人民共和国,人民,人,民,共和国,共和,和,国国,国歌”，会穷尽各种可能的组合，适合 Term Query；<br/>
ik_smart: 会做最粗粒度的拆分，比如会将“中华人民共和国国歌”拆分为“中华人民共和国,国歌”，适合 Phrase 查询。</p>

<h2 id="toc_5">自定义中文分词库</h2>

<blockquote>
<p>因为有些词汇是一些网络用语，在中文分词的时候，会将其拆分开来，不能达到我们想要的效果，因此需要我们自定义分词库，来解析出这些词汇。<br/>
ik分词器已经有了自定义分词库的方法，按照文档上描述操作即可。</p>
</blockquote>

<h3 id="toc_6">操作方法</h3>

<p>找到ik插件下，config目录下的：IKAnalyzer.cfg.xml配置文件<br/>
编辑如下配置：</p>

<pre><code class="language-text">&lt;!DOCTYPE properties SYSTEM &quot;http://java.sun.com/dtd/properties.dtd&quot;&gt;
&lt;properties&gt;
        &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt;
        &lt;!--用户可以在这里配置自己的扩展字典 --&gt;
        &lt;entry key=&quot;ext_dict&quot;&gt;custom.dic&lt;/entry&gt;
         &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt;
        &lt;entry key=&quot;ext_stopwords&quot;&gt;&lt;/entry&gt;
        &lt;!--用户可以在这里配置远程扩展字典 --&gt;
        &lt;!-- &lt;entry key=&quot;remote_ext_dict&quot;&gt;words_location&lt;/entry&gt; --&gt;
        &lt;!--用户可以在这里配置远程扩展停止词字典--&gt;
        &lt;!-- &lt;entry key=&quot;remote_ext_stopwords&quot;&gt;words_location&lt;/entry&gt; --&gt;
&lt;/properties&gt;
</code></pre>

<p>然后在同级目录下创建一个：custom.dic文件，将自己需要的词汇添加到这个文件，每行一个词汇。然后保存，重启ES即可。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ES文档的乐观锁控制]]></title>
    <link href="jythons.github.io/16103778537691.html"/>
    <updated>2021-01-11T23:10:53+08:00</updated>
    <id>jythons.github.io/16103778537691.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>文档的乐观锁，文档数据内有很多的源数据，其中_version就是用来控制文档的乐观锁的，如果文档被删除或者修改，他的_version会累加，如果有多个线程或用户同时去更新同一个数据，ES会判断数据的版本号，如果版本号匹配，则可以更新，如果版本号不匹配，就不允许更新。</p>
</blockquote>

<span id="more"></span><!-- more -->

<h2 id="toc_0">ES乐观锁的使用</h2>

<p>当我们要使用乐观锁去控制ES数据的时候，可以使用下面的方法去实现。<br/>
使用乐观锁会涉及到两个参数，分别是: _seq_no和_primary_term,<br/>
_seq_no: 类似于版本号，会像_version一样去增长<br/>
_primary_term: 表示数据在集群中的位置信息</p>

<p>使用方式：</p>

<table>
<thead>
<tr>
<th>请求方式</th>
<th>POST</th>
</tr>
</thead>

<tbody>
<tr>
<td>请求地址</td>
<td><a href="http://192.168.3.214:9200/index/_doc/1?if_seq_no=30&amp;if_primary_term=1">http://192.168.3.214:9200/index/_doc/1?if_seq_no=30&amp;if_primary_term=1</a></td>
</tr>
</tbody>
</table>

<blockquote>
<p>ES 老的版本只使用_version 去控制锁的机制，新版本中使用_seq_no和_primary_term两个字段去控制。</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ES数据类型]]></title>
    <link href="jythons.github.io/16093421785520.html"/>
    <updated>2020-12-30T23:29:38+08:00</updated>
    <id>jythons.github.io/16093421785520.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<h2 id="toc_0">核心数据类型</h2>

<h3 id="toc_1">字符串类型 - string（不在支持）</h3>

<h4 id="toc_2">使用示例</h4>

<pre><code class="language-text">PUT website
{
    &quot;mappings&quot;: {
        &quot;blog&quot;: {
            &quot;properties&quot;: {
                &quot;title&quot;: {&quot;type&quot;: &quot;string&quot;},    // 全文本
                &quot;tags&quot;: {&quot;type&quot;: &quot;string&quot;, &quot;index&quot;: &quot;not_analyzed&quot;} // 关键字, 不分词
            }
        }
    }
}
</code></pre>

<h4 id="toc_3">ES 5.6.10中的响应信息</h4>

<pre><code class="language-text">#! Deprecation: The [string] field is deprecated, please use [text] or [keyword] instead on [tags]
#! Deprecation: The [string] field is deprecated, please use [text] or [keyword] instead on [title]
{
  &quot;acknowledged&quot;: true,
  &quot;shards_acknowledged&quot;: true,
  &quot;index&quot;: &quot;website&quot;
}
</code></pre>

<h4 id="toc_4">ES 6.6.0中的响应信息</h4>

<pre><code class="language-text">{
  &quot;error&quot;: {
    &quot;root_cause&quot;: [
      {
        &quot;type&quot;: &quot;mapper_parsing_exception&quot;,
        &quot;reason&quot;: &quot;No handler for type [string] declared on field [title]&quot;
      }
    ],
    &quot;type&quot;: &quot;mapper_parsing_exception&quot;,
    &quot;reason&quot;: &quot;Failed to parse mapping [blog]: No handler for type [string] declared on field [title]&quot;,
    &quot;caused_by&quot;: {
      &quot;type&quot;: &quot;mapper_parsing_exception&quot;,
      &quot;reason&quot;: &quot;No handler for type [string] declared on field [title]&quot;
    }
  },
  &quot;status&quot;: 400
}
</code></pre>

<blockquote>
<p>string类型的field已经被移除了，我们需要使用text或keyword类型来代替string。</p>
</blockquote>

<h3 id="toc_5">文本类型 - text</h3>

<p>在ES5.4版本开始，text取代了需要分词的string。<br/>
当一个字段需要使用与全文搜索（会被分词），比如产品名称、产品描述信息，就应该使用text类型。</p>

<blockquote>
<p>text的内容会被分词，可以设置是否需要存储：<code>&quot;index&quot;: &quot;true|false&quot;</code>.<br/>
text类型的字段不能用于排序，也很少用于聚合。</p>
</blockquote>

<h4 id="toc_6">使用示例</h4>

<pre><code class="language-text">PUT website
{
    &quot;mappings&quot;: {
        &quot;blog&quot;: {
            &quot;properties&quot;: {
                &quot;summary&quot;: {&quot;type&quot;: &quot;text&quot;, &quot;index&quot;: &quot;true&quot;}
            }
        }
    }
}
</code></pre>

<h3 id="toc_7">关键字类型 - keyword</h3>

<p>在ES5.4版本开始，keyword取代了不需要分词的string。<br/>
当一个字段需要按照精确值进行过滤、排序、聚合等操作时，就应该使用keyword类型。</p>

<blockquote>
<p>keyword的内容不会被分词，可以设置是否需要存储：<code>&quot;index&quot;: &quot;true|false&quot;</code></p>
</blockquote>

<h4 id="toc_8">使用示例</h4>

<pre><code class="language-text">PUT website
{
    &quot;mappings&quot;: {
        &quot;blog&quot;: {
            &quot;properties&quot;: {
                &quot;tags&quot;: {&quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: &quot;true&quot;}
            }
        }
    }
}
</code></pre>

<h3 id="toc_9">数字类型 - 8种</h3>

<table>
<thead>
<tr>
<th>类型</th>
<th>说明</th>
</tr>
</thead>

<tbody>
<tr>
<td>byte</td>
<td>有符号的8位整数，范围：[-128 ~ 127]</td>
</tr>
<tr>
<td>short</td>
<td>有符号的16位整数，范围：[-32768 ~ 32767]</td>
</tr>
<tr>
<td>integer</td>
<td>有符号的32位整数，范围：[-2<sup>31</sup> ~ 2<sup>31-1]</sup></td>
</tr>
<tr>
<td>long</td>
<td>有符号的64位整数，范围：[-2<sup>63</sup> ~ 2<sup>63-1]</sup></td>
</tr>
<tr>
<td>float</td>
<td>32位单精度浮点数</td>
</tr>
<tr>
<td>double</td>
<td>64位双精度浮点数</td>
</tr>
<tr>
<td>half_float</td>
<td>16位半精度IEEE 754浮点类型</td>
</tr>
<tr>
<td>scaled_float</td>
<td>缩放类型的浮点数，比如price字段只需要精确到分，57.34缩放因子为100，存储结果为5734</td>
</tr>
</tbody>
</table>

<blockquote>
<p>使用注意事项：<br/>
尽可能选择范围小的数据类型，字段的长度越短，索引和搜索的效率越高；<br/>
优先考虑使用带缩放因子的浮点类型。</p>
</blockquote>

<h4 id="toc_10">使用示例</h4>

<pre><code class="language-text">PUT shop
{
    &quot;mappings&quot;: {
        &quot;book&quot;: {
            &quot;properties&quot;: {
                &quot;name&quot;: {&quot;type&quot;: &quot;text&quot;},
                &quot;quantity&quot;: {&quot;type&quot;: &quot;integer&quot;},  // integer类型
                &quot;price&quot;: {
                    &quot;type&quot;: &quot;scaled_float&quot;,       // scaled_float类型
                    &quot;scaling_factor&quot;: 100
                }
            }
        }
    }
}
</code></pre>

<h3 id="toc_11">日期类型 - date</h3>

<p>JSON没有日期数据类型，所以在ES中，日期可以是：</p>

<ul>
<li>包含格式化日期的字符串，&quot;2020-12-30&quot;，或&quot;2020-12-30 12:00:00&quot;</li>
<li>代表时间毫秒数的长整型数字</li>
<li>代表时间秒数的整数</li>
</ul>

<blockquote>
<p>如果时区未指定，日期将被转换为UTC格式，单存储的却是长整型的毫秒值<br/>
可以自定义日期格式，若未指定，则使用默认格式：<code>strict_date_optional_time|epoch_millis</code></p>
</blockquote>

<h4 id="toc_12">使用日期格式示例</h4>

<pre><code class="language-text">// 添加映射
PUT website
{
    &quot;mappings&quot;: {
        &quot;blog&quot;: {
            &quot;properties&quot;: {
                &quot;pub_date&quot;: {&quot;type&quot;: &quot;date&quot;}   // 日期类型
            }
        }
    }
}

// 添加数据
PUT website/blog/11
{ &quot;pub_date&quot;: &quot;2018-10-10&quot; }

PUT website/blog/12
{ &quot;pub_date&quot;: &quot;2018-10-10T12:00:00Z&quot; }  // Solr中默认使用的日期格式

PUT website/blog/13
{ &quot;pub_date&quot;: &quot;1589584930103&quot; }         // 时间的毫秒值
</code></pre>

<h4 id="toc_13">多种日期格式</h4>

<blockquote>
<p>多个格式使用双竖线<code>||</code>分隔，每个格式都会被依次尝试，直到找到匹配的<br/>
第一个格式用于将时间毫秒值转换为对应格式的字符串。</p>
</blockquote>

<h5 id="toc_14">使用示例</h5>

<pre><code class="language-text">// 添加映射
PUT website
{
    &quot;mappings&quot;: {
        &quot;blog&quot;: {
            &quot;properties&quot;: {
                &quot;date&quot;: {
                    &quot;type&quot;: &quot;date&quot;,  // 可以接受如下类型的格式
                    &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;
                }
            }
        }
    }
}
</code></pre>

<h3 id="toc_15">布尔类型 - boolean</h3>

<p>可以接受表示真、假的字符串或数字：</p>

<ul>
<li>真值：true, &quot;true&quot;, &quot;on&quot;, &quot;yes&quot;, &quot;1&quot; ...</li>
<li>假值: false, &quot;false&quot;, &quot;off&quot;, &quot;no&quot;, &quot;0&quot;, &quot;&quot;(空字符串), 0.0, 0</li>
</ul>

<h3 id="toc_16">二进制型 - binary</h3>

<p>二进制类型是Base64编码字符串的二进制值, 不以默认的方式存储, 且不能被搜索. 有2个设置项:</p>

<blockquote>
<p>doc_values: 该字段是否需要存储到磁盘上, 方便以后用来排序、聚合或脚本查询. 接受true和false(默认);<br/>
store: 该字段的值是否要和_source分开存储、检索, 意思是除了_source中, 是否要单独再存储一份. 接受true或false(默认).</p>
</blockquote>

<h4 id="toc_17">使用示例</h4>

<pre><code class="language-text">// 添加映射
PUT website
{
    &quot;mappings&quot;: {
        &quot;blog&quot;: {
            &quot;properties&quot;: {
                &quot;blob&quot;: {&quot;type&quot;: &quot;binary&quot;}   // 二进制
            }
        }
    }
}
// 添加数据
PUT website/blog/1
{
    &quot;title&quot;: &quot;Some binary blog&quot;,
    &quot;blob&quot;: &quot;hED903KSrA084fRiD5JLgY==&quot;
}
</code></pre>

<blockquote>
<p>注意: Base64编码的二进制值不能嵌入换行符\n, 逗号(0x2c)等符号.</p>
</blockquote>

<h3 id="toc_18">范围类型 - range</h3>

<p>range类型支持一下几种：</p>

<table>
<thead>
<tr>
<th style="text-align: left">类型</th>
<th style="text-align: left">范围</th>
</tr>
</thead>

<tbody>
<tr>
<td style="text-align: left">integer_range</td>
<td style="text-align: left">−2<sup>31</sup> ~ 2<sup>31−1</sup></td>
</tr>
<tr>
<td style="text-align: left">long_range</td>
<td style="text-align: left">−2<sup>63</sup> ~ 2<sup>63−1</sup></td>
</tr>
<tr>
<td style="text-align: left">float_range</td>
<td style="text-align: left">32位单精度浮点型</td>
</tr>
<tr>
<td style="text-align: left">double_range</td>
<td style="text-align: left">64位双精度浮点型</td>
</tr>
<tr>
<td style="text-align: left">date_range</td>
<td style="text-align: left">64位整数, 毫秒计时</td>
</tr>
<tr>
<td style="text-align: left">ip_range</td>
<td style="text-align: left">IP值的范围, 支持IPV4和IPV6, 或者这两种同时存在</td>
</tr>
</tbody>
</table>

<h4 id="toc_19">添加映射</h4>

<pre><code class="language-text">PUT company
{
    &quot;mappings&quot;: {
        &quot;department&quot;: {
            &quot;properties&quot;: {
                &quot;expected_number&quot;: {  // 预期员工数
                    &quot;type&quot;: &quot;integer_range&quot;
                },
                &quot;time_frame&quot;: {       // 发展时间线
                    &quot;type&quot;: &quot;date_range&quot;, 
                    &quot;format&quot;: &quot;yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis&quot;
                },
                &quot;ip_whitelist&quot;: {     // ip白名单
                    &quot;type&quot;: &quot;ip_range&quot;
                }
            }
        }
    }
}
</code></pre>

<h4 id="toc_20">添加数据</h4>

<pre><code class="language-text">PUT company/department/1
{
    &quot;expected_number&quot; : {
        &quot;gte&quot; : 10,
        &quot;lte&quot; : 20
    },
    &quot;time_frame&quot; : { 
        &quot;gte&quot; : &quot;2018-10-01 12:00:00&quot;, 
        &quot;lte&quot; : &quot;2018-11-01&quot;
    }, 
    &quot;ip_whitelist&quot;: &quot;192.168.0.0/16&quot;
}
</code></pre>

<p>查询数据</p>

<pre><code class="language-text">GET company/department/_search
{
    &quot;query&quot;: {
        &quot;term&quot;: {
            &quot;expected_number&quot;: {
                &quot;value&quot;: 12
            }
        }
    }
}
GET company/department/_search
{
    &quot;query&quot;: {
        &quot;range&quot;: {
            &quot;time_frame&quot;: {
                &quot;gte&quot;: &quot;208-08-01&quot;,
                &quot;lte&quot;: &quot;2018-12-01&quot;,
                &quot;relation&quot;: &quot;within&quot; 
            }
        }
    }
}
</code></pre>

<h4 id="toc_21">查询结果</h4>

<pre><code class="language-text">{
  &quot;took&quot;: 26,
  &quot;timed_out&quot;: false,
  &quot;_shards&quot;: {
    &quot;total&quot;: 5,
    &quot;successful&quot;: 5,
    &quot;skipped&quot;: 0,
    &quot;failed&quot;: 0
  },
  &quot;hits&quot;: {
    &quot;total&quot;: 1,
    &quot;max_score&quot;: 1.0,
    &quot;hits&quot;: [
      {
        &quot;_index&quot;: &quot;company&quot;,
        &quot;_type&quot;: &quot;department&quot;,
        &quot;_id&quot;: &quot;1&quot;,
        &quot;_score&quot;: 1.0,
        &quot;_source&quot;: {
          &quot;expected_number&quot;: {
            &quot;gte&quot;: 10,
            &quot;lte&quot;: 20
          },
          &quot;time_frame&quot;: {
            &quot;gte&quot;: &quot;2018-10-01 12:00:00&quot;,
            &quot;lte&quot;: &quot;2018-11-01&quot;
          },
          &quot;ip_whitelist&quot; : &quot;192.168.0.0/16&quot;
        }
      }
    ]
  }
}
</code></pre>

<h2 id="toc_22">复杂数据类型</h2>

<h3 id="toc_23">数组类型 - array</h3>

<p>ES中没有专门的数组类型，直接使用[]定义即可；<br/>
数组中所有的值必须是同一种数据类型, 不支持混合数据类型的数组</p>

<blockquote>
<p>字符串数组: [&quot;one&quot;, &quot;two&quot;];<br/>
整数数组: [1, 2];<br/>
由数组组成的数组: [1, [2, 3]], 等价于[1, 2, 3];<br/>
对象数组: [{&quot;name&quot;: &quot;Tom&quot;, &quot;age&quot;: 20}, {&quot;name&quot;: &quot;Jerry&quot;, &quot;age&quot;: 18}].</p>
</blockquote>

<p>注意</p>

<blockquote>
<p>动态添加数据时, 数组中第一个值的类型决定整个数组的类型;<br/>
不支持混合数组类型, 比如[1, &quot;abc&quot;];<br/>
数组可以包含null值, 空数组[]会被当做missing field —— 没有值的字段.</p>
</blockquote>

<h3 id="toc_24">对象类型 - object</h3>

<p>JSON文档是分层的: 文档可以包含内部对象, 内部对象也可以包含内部对象。</p>

<h4 id="toc_25">使用示例</h4>

<pre><code class="language-text">PUT employee/developer/1
{
    &quot;name&quot;: &quot;ma_shoufeng&quot;,
    &quot;address&quot;: {
        &quot;region&quot;: &quot;China&quot;,
        &quot;location&quot;: {&quot;province&quot;: &quot;GuangDong&quot;, &quot;city&quot;: &quot;GuangZhou&quot;}
    }
}
</code></pre>

<h4 id="toc_26">存储方式</h4>

<pre><code class="language-text">{
    &quot;name&quot;:                       &quot;ma_shoufeng&quot;,
    &quot;address.region&quot;:             &quot;China&quot;,
    &quot;address.location.province&quot;:  &quot;GuangDong&quot;, 
    &quot;address.location.city&quot;:      &quot;GuangZhou&quot;
}
</code></pre>

<h4 id="toc_27">文档的映射结构类似为</h4>

<pre><code class="language-text">PUT employee
{
    &quot;mappings&quot;: {
        &quot;developer&quot;: {
            &quot;properties&quot;: {
                &quot;name&quot;: { &quot;type&quot;: &quot;text&quot;, &quot;index&quot;: &quot;true&quot; }, 
                &quot;address&quot;: {
                    &quot;properties&quot;: {
                        &quot;region&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: &quot;true&quot; },
                        &quot;location&quot;: {
                            &quot;properties&quot;: {
                                &quot;province&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: &quot;true&quot; },
                                &quot;city&quot;: { &quot;type&quot;: &quot;keyword&quot;, &quot;index&quot;: &quot;true&quot; }
                            }
                        }
                    }
                }
            }
        }
    }
}
</code></pre>

<h3 id="toc_28">嵌套类型 - nested</h3>

<p>嵌套类型是对象数据类型的一个特例, 可以让array类型的对象被独立索引和搜索.</p>

<h4 id="toc_29">对象数组是如何存储的</h4>

<h5 id="toc_30">添加数据</h5>

<pre><code class="language-text">PUT game_of_thrones/role/1
{
    &quot;group&quot;: &quot;stark&quot;,
    &quot;performer&quot;: [
        {&quot;first&quot;: &quot;John&quot;, &quot;last&quot;: &quot;Snow&quot;},
        {&quot;first&quot;: &quot;Sansa&quot;, &quot;last&quot;: &quot;Stark&quot;}
    ]
}
</code></pre>

<h5 id="toc_31">内部存储结构</h5>

<pre><code class="language-text">{
    &quot;group&quot;:             &quot;stark&quot;,
    &quot;performer.first&quot;: [ &quot;john&quot;, &quot;sansa&quot; ],
    &quot;performer.last&quot;:  [ &quot;snow&quot;, &quot;stark&quot; ]
}
</code></pre>

<h5 id="toc_32">存储分析</h5>

<p>可以看出, user.first和user.last会被平铺为多值字段, 这样一来, John和Snow之间的关联性就丢失了.<br/>
在查询时, 可能出现John Stark的结果.</p>

<h4 id="toc_33">用nested类型解决object类型的不足</h4>

<p>如果需要对以最对象进行索引, 且保留数组中每个对象的独立性, 就应该使用嵌套数据类型.<br/>
嵌套对象实质是将每个对象分离出来, 作为隐藏文档进行索引.</p>

<h5 id="toc_34">创建映射</h5>

<pre><code class="language-text">PUT game_of_thrones
{
    &quot;mappings&quot;: {
        &quot;role&quot;: {
            &quot;properties&quot;: {
                &quot;performer&quot;: {&quot;type&quot;: &quot;nested&quot; }
            }
        }
    }
}
</code></pre>

<h5 id="toc_35">添加映射</h5>

<pre><code class="language-text">PUT game_of_thrones/role/1
{
    &quot;group&quot; : &quot;stark&quot;,
    &quot;performer&quot; : [
        {&quot;first&quot;: &quot;John&quot;, &quot;last&quot;: &quot;Snow&quot;},
        {&quot;first&quot;: &quot;Sansa&quot;, &quot;last&quot;: &quot;Stark&quot;}
    ]
}
</code></pre>

<h5 id="toc_36">检索数据</h5>

<pre><code class="language-text">GET game_of_thrones/_search
{
    &quot;query&quot;: {
        &quot;nested&quot;: {
            &quot;path&quot;: &quot;performer&quot;,
            &quot;query&quot;: {
                &quot;bool&quot;: {
                    &quot;must&quot;: [
                        { &quot;match&quot;: { &quot;performer.first&quot;: &quot;John&quot; }},
                        { &quot;match&quot;: { &quot;performer.last&quot;:  &quot;Snow&quot; }} 
                    ]
                }
            }, 
            &quot;inner_hits&quot;: {
                &quot;highlight&quot;: {
                    &quot;fields&quot;: {&quot;performer.first&quot;: {}}
                }
            }
        }
    }
}
</code></pre>

<h2 id="toc_37">地理数据类型</h2>

<h3 id="toc_38">地理点类型 - geo point</h3>

<p>地理点类型用于存储地理位置的经纬度对, 可用于:</p>

<ul>
<li>查找一定范围内的地理点;</li>
<li>通过地理位置或相对某个中心点的距离聚合文档;</li>
<li>将距离整合到文档的相关性评分中;</li>
<li>通过距离对文档进行排序.</li>
</ul>

<h4 id="toc_39">添加映射</h4>

<pre><code class="language-text">PUT employee
{
    &quot;mappings&quot;: {
        &quot;developer&quot;: {
            &quot;properties&quot;: {
                &quot;location&quot;: {&quot;type&quot;: &quot;geo_point&quot;}
            }
        }
    }
}
</code></pre>

<h4 id="toc_40">存储地理位置</h4>

<pre><code class="language-text">// 方式一: 纬度 + 经度键值对
PUT employee/developer/1
{
    &quot;text&quot;: &quot;小蛮腰-键值对地理点参数&quot;, 
    &quot;location&quot;: {
        &quot;lat&quot;: 23.11, &quot;lon&quot;: 113.33     // 纬度: latitude, 经度: longitude
    }
}

// 方式二: &quot;纬度, 经度&quot;的字符串参数
PUT employee/developer/2
{
  &quot;text&quot;: &quot;小蛮腰-字符串地理点参数&quot;,
  &quot;location&quot;: &quot;23.11, 113.33&quot;           // 纬度, 经度
}

// 方式三: [&quot;经度, 纬度&quot;] 数组地理点参数
PUT employee/developer/3
{
  &quot;text&quot;: &quot;小蛮腰-数组参数&quot;,
  &quot;location&quot;: [ 113.33, 23.11 ]         // 经度, 纬度
}
</code></pre>

<h4 id="toc_41">查询示例</h4>

<pre><code class="language-text">GET employee/_search
{
    &quot;query&quot;: { 
        &quot;geo_bounding_box&quot;: { 
            &quot;location&quot;: {
                &quot;top_left&quot;: { &quot;lat&quot;: 24, &quot;lon&quot;: 113 },      // 地理盒子模型的上-左边
                &quot;bottom_right&quot;: { &quot;lat&quot;: 22, &quot;lon&quot;: 114 }   // 地理盒子模型的下-右边
            }
        }
    }
}
</code></pre>

<h3 id="toc_42">地理形状类型 - geo_shape</h3>

<p>是多边形的复杂形状. 使用较少, 这里省略.<br/>
可以参考这篇文章: <a href="https://blog.csdn.net/u012332735/article/details/54971638">Elasticsearch地理位置总结</a></p>

<h2 id="toc_43">专门数据类型</h2>

<h3 id="toc_44">IP类型</h3>

<p>IP类型的字段用于存储IPv4或IPv6的地址, 本质上是一个长整型字段.</p>

<h4 id="toc_45">添加映射</h4>

<pre><code class="language-text">PUT employee
{
    &quot;mappings&quot;: {
        &quot;customer&quot;: {
            &quot;properties&quot;: {
                &quot;ip_addr&quot;: { &quot;type&quot;: &quot;ip&quot; }
            }
        }
    }
}
</code></pre>

<h4 id="toc_46">添加数据</h4>

<pre><code class="language-text">PUT employee/customer/1
{ &quot;ip_addr&quot;: &quot;192.168.1.1&quot; }
</code></pre>

<h4 id="toc_47">查询数据</h4>

<pre><code class="language-text">GET employee/customer/_search
{
    &quot;query&quot;: {
        &quot;term&quot;: { &quot;ip_addr&quot;: &quot;192.168.0.0/16&quot; }
    }
}
</code></pre>

<h3 id="toc_48">计数数据类型 - token_count</h3>

<p>token_count类型用于统计字符串中的单词数量.<br/>
本质上是一个整数型字段, 接受并分析字符串值, 然后索引字符串中单词的个数.</p>

<h4 id="toc_49">添加映射</h4>

<pre><code class="language-text">PUT employee
{
    &quot;mappings&quot;: {
        &quot;customer&quot;: {
            &quot;properties&quot;: {
                &quot;name&quot;: { 
                    &quot;type&quot;: &quot;text&quot;,
                    &quot;fields&quot;: {
                        &quot;length&quot;: {
                            &quot;type&quot;: &quot;token_count&quot;, 
                            &quot;analyzer&quot;: &quot;standard&quot;
                        }
                    }
                }
            }
        }
    }
}
</code></pre>

<h4 id="toc_50">添加数据</h4>

<pre><code class="language-text">PUT employee/customer/1
{ &quot;name&quot;: &quot;John Snow&quot; }
PUT employee/customer/2
{ &quot;name&quot;: &quot;Tyrion Lannister&quot; }
</code></pre>

<h4 id="toc_51">查询数据</h4>

<pre><code class="language-text">GET employee/customer/_search
{
    &quot;query&quot;: {
        &quot;term&quot;: { &quot;name.length&quot;: 2 }
    }
}
</code></pre>

<h2 id="toc_52">参考</h2>

<p><a href="https://www.cnblogs.com/shoufeng/p/10692113.html">ES 15 - Elasticsearch的数据类型 (text、keyword、date、object、geo等)</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ES基本操作]]></title>
    <link href="jythons.github.io/16093414600296.html"/>
    <updated>2020-12-30T23:17:40+08:00</updated>
    <id>jythons.github.io/16093414600296.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<h2 id="toc_0">Mappings自定义创建映射</h2>

<h3 id="toc_1">创建mapping</h3>

<pre><code class="language-text">接口地址：http://es_service_addr/索引名称
请求方式：put
body: 
    {
        &quot;mappings&quot;: {
           # 属性
            &quot;properties&quot;: {
               # 字段
                &quot;realname&quot;: {
                    &quot;type&quot;: &quot;text&quot;,
                    &quot;index&quot;: true  # index表示是否需要索引，true表示需要（默认），false表示不需要索引，需要索引就表示会被分词
                }
            }
        }
    }
</code></pre>

<blockquote>
<p>mapping一旦创建，就不能够在修改。如果需要修改，要把现有的索引删除，重新添加。<br/>
如果需要添加，可以post访问：http://es_service_addr/索引名称/_mapping, 参数格式同上面相同，注意增加需要去掉mappings，直接写properties。</p>

<h3 id="toc_2">响应</h3>
</blockquote>

<pre><code class="language-text">{
    &quot;acknowledged&quot;: true,
    &quot;shards_acknowledged&quot;: true,
    &quot;index&quot;: &quot;index_mapping&quot;
}
</code></pre>

<h3 id="toc_3">分析是否分词</h3>

<pre><code class="language-text">接口地址：http://es_service_addr/索引名称/_analyze
请求方式：GET
body:
{
    &quot;field&quot;: &quot;realname&quot;, # 分析的字段
    &quot;text&quot;: &quot;我爱我的祖国&quot; # 分析字段对应的值
}
</code></pre>

<p>响应：</p>

<pre><code class="language-text">{
    &quot;tokens&quot;: [
        {
            &quot;token&quot;: &quot;我&quot;,
            &quot;start_offset&quot;: 0,
            &quot;end_offset&quot;: 1,
            &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,
            &quot;position&quot;: 0
        },
        {
            &quot;token&quot;: &quot;爱&quot;,
            &quot;start_offset&quot;: 1,
            &quot;end_offset&quot;: 2,
            &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,
            &quot;position&quot;: 1
        },
        {
            &quot;token&quot;: &quot;我&quot;,
            &quot;start_offset&quot;: 2,
            &quot;end_offset&quot;: 3,
            &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,
            &quot;position&quot;: 2
        },
        {
            &quot;token&quot;: &quot;的&quot;,
            &quot;start_offset&quot;: 3,
            &quot;end_offset&quot;: 4,
            &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,
            &quot;position&quot;: 3
        },
        {
            &quot;token&quot;: &quot;祖&quot;,
            &quot;start_offset&quot;: 4,
            &quot;end_offset&quot;: 5,
            &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,
            &quot;position&quot;: 4
        },
        {
            &quot;token&quot;: &quot;国&quot;,
            &quot;start_offset&quot;: 5,
            &quot;end_offset&quot;: 6,
            &quot;type&quot;: &quot;&lt;IDEOGRAPHIC&gt;&quot;,
            &quot;position&quot;: 5
        }
    ]
}
</code></pre>

<blockquote>
<p>默认是支持英文的分词，所以上面的返回值把中文拆解成了单独的汉字，如果要使用英文可以去做拓展。</p>
</blockquote>

<h2 id="toc_4">文档的基本操作</h2>

<h3 id="toc_5">添加文档与自动映射</h3>

<pre><code class="language-text">创建文档
接口地址：http://es_service_addr/my_doc/_doc/1
    my_doc：索引名称
    _doc: 操作类型
    1：ES主键
body:
{
    &quot;id&quot;: 1001,
    &quot;name&quot;: &quot;no-1&quot;,
    &quot;desc&quot;: &quot;we are number one&quot;,
    &quot;create_date&quot;: &quot;2021-01-05&quot;
}

响应：
{
    &quot;_index&quot;: &quot;my_doc&quot;,
    &quot;_type&quot;: &quot;_doc&quot;,
    &quot;_id&quot;: &quot;ulVN03YBVWKanGeCxsTB&quot;,
    &quot;_version&quot;: 1,
    &quot;result&quot;: &quot;created&quot;,
    &quot;_shards&quot;: {
        &quot;total&quot;: 1,
        &quot;successful&quot;: 1,
        &quot;failed&quot;: 0
    },
    &quot;_seq_no&quot;: 0,
    &quot;_primary_term&quot;: 1
}
</code></pre>

<h3 id="toc_6">删除文档内的数据</h3>

<pre><code class="language-text">接口地址: http://es_service_addr/my_doc/_doc/1
访求方式：delete
解析: 表示删除索引my_doc下的_id=1的文档数据
</code></pre>

<blockquote>
<p>删除操作其实不是物理删除，实际上是逻辑删除，通过添加逻辑标识符来判断是否删除，当磁盘数据过载后，才会去删除被标记为删除的数据</p>
</blockquote>

<h3 id="toc_7">修改文档数据</h3>

<pre><code class="language-text">接口地址: http://es_service_addr/my_doc/_doc/1/_update
请求方式：post
解析: 修改索引为my_doc数据_id=1的文档数据内容

body:
{
    &quot;doc&quot;: {
        &quot;name&quot;:&quot;abc&quot;
    }
}
</code></pre>

<blockquote>
<p>这种对某个字段数据进行局部的修改，实际上在ES底层是将数据重新写了一次，并不是对这个字段修改了一下。我们自己也可以添加一个全字段的数据，ID与原来的相同，这样也可以做到更新数据的作用。</p>
</blockquote>

<h3 id="toc_8">查询文档数据</h3>

<pre><code class="language-text">请求方式：GET
请求地址：http://es_service_addr/my_doc/_doc/1?_source=id,name
解析：查询文档_doc下索引my_doc，索引_id=1的数据，并且只查询id和name这两个字段的数据

查询所有数据的id和name
http://es_service_addr/my_doc/_doc/_search?_source=id,name
</code></pre>

<h4 id="toc_9">判断查询数据是否存在</h4>

<table>
<thead>
<tr>
<th>请求方式</th>
<th>HEAD</th>
</tr>
</thead>

<tbody>
<tr>
<td>请求地址</td>
<td>http://es_service_addr/my_doc/_doc/1</td>
</tr>
</tbody>
</table>

<blockquote>
<p>如果请求状态码返回200，表示数据存在，请求状态码返回404，表示数据不存在</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch安装]]></title>
    <link href="jythons.github.io/16090525942611.html"/>
    <updated>2020-12-27T15:03:14+08:00</updated>
    <id>jythons.github.io/16090525942611.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">下载地址</h2>

<p><a href="https://www.elastic.co/cn/elasticsearch/">官方下载</a></p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">安装方法</h2>

<p>1.下载安装包解压</p>

<pre><code class="language-text">tar -zxvf elasticsearch.tar.gz
</code></pre>

<p>2.将解压出来的文件夹转移到/user/lcoal文件夹下</p>

<pre><code class="language-text">mv elasticsearch /usr/local/
</code></pre>

<p>3.创建一个用于存放数据的目录</p>

<pre><code class="language-text">cd /usr/lcoal/elasticsearch/
mkdir data
</code></pre>

<p>4.修改核心配置文件</p>

<pre><code class="language-text">vim ./config/elasticsearch.yml

# 配置文件解析
cluster.name: my-application                # 集群名称
node.name: node-name                        # 节点名称
# paths相关配置
path.data: /usr/lcoal/elasticsearch/data    # 存放数据的目录
path.logs: /usr/lcoal/elasticsearch/logs    # 存放日志的目录
# 网络相关的配置
network.host: 0.0.0.0
http.port: 9200 
# 配置跨域访问
http.cors.enabled: true
http.core.allow-origin: &quot;*&quot;
# 节点相关的配置
# 这里的节点名称要与上面配置的node.name的名称相同
cluster.initial_master_nodes: [&quot;node-1&quot;, &quot;node-2&quot;]
</code></pre>

<pre><code class="language-text">vim ./config/jvm.options

修改内存大小
-Xms1g # 初始化内存空间，默认1G，虚拟机建议修改为128m
-Xmx1g # 最大使用内存空间，默认1G，虚拟机建议修改为128m
</code></pre>

<blockquote>
<p>ES是不允许使用root用户启动的，启动ES需要使用非root用户启动。<br/>
创建一个新用户：useradd esuser<br/>
为esuser用户授权：chown -R esuser:esuser /usr/lcoal/elasticsearch</p>
</blockquote>

<p>5.启动ES<br/>
进入到/usr/lcoal/elasticsearch/bin目录下</p>

<pre><code class="language-text">切换为esuser用户
su esuser
启动ES
./elasticsearch
</code></pre>

<blockquote>
<p>启动时可能会遇到的错误<br/>
1.max file descriptors [4096] for elasticsearch process is too low, increase to at least [65535]<br/>
2.max number of threads [3756] for user [esuser] is too low, increase to at least [4096]<br/>
3.max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]<br/>
问题1：能够打开的文件数过少<br/>
问题2：支持的最大线程数过少<br/>
问题3：支持最大虚拟内存vm.max_map_count数太低<br/>
解决以上问题，需要修改配置文件: /etc/security/limits.conf<br/>
添加如下配置：</p>

<pre><code class="language-text">* soft nofile 65536
* hard nofile 131072
* soft nproc 4096
* hard nproc 4096
</code></pre>

<p>然后在/etc/sysctl.d文件内添加如下配置：</p>

<pre><code class="language-text">vm.max_map_count=262145
</code></pre>

<p>修改/etc/sysctl.d文件需要刷新：<code>sysctl -p</code><br/>
如果还是不能启动，重启服务器即可</p>
</blockquote>

<p>6.后台启动ES</p>

<pre><code class="language-text">./elasticsearch -d
</code></pre>

<h2 id="toc_2">文件解析</h2>

<table>
<thead>
<tr>
<th>文件夹</th>
<th>子文件</th>
<th>作用</th>
<th>备注</th>
</tr>
</thead>

<tbody>
<tr>
<td>bin</td>
<td></td>
<td>可执行文件等</td>
<td></td>
</tr>
<tr>
<td>config</td>
<td></td>
<td>配置</td>
<td></td>
</tr>
<tr>
<td></td>
<td>elasticsearch.yml</td>
<td>核心配置文件</td>
<td></td>
</tr>
<tr>
<td>jdk</td>
<td></td>
<td>java依赖</td>
<td></td>
</tr>
<tr>
<td>lib</td>
<td></td>
<td>工具类</td>
<td></td>
</tr>
<tr>
<td>logs</td>
<td></td>
<td>日志</td>
<td></td>
</tr>
<tr>
<td>modules</td>
<td></td>
<td>ES模块</td>
<td></td>
</tr>
<tr>
<td>plugins</td>
<td></td>
<td>ES拓展</td>
<td></td>
</tr>
<tr>
<td>data</td>
<td></td>
<td>用于存放数据</td>
<td>自己创建</td>
</tr>
</tbody>
</table>

<h2 id="toc_3">安装ES可视化插件（elasticsearch-head）</h2>

<p><a href="https://github.com/mobz/elasticsearch-head">elasticsearch-head</a>插件可以去上去下载，具体安装方法可以参考GitHub的README.md说明。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch原理]]></title>
    <link href="jythons.github.io/16076110407363.html"/>
    <updated>2020-12-10T22:37:20+08:00</updated>
    <id>jythons.github.io/16076110407363.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<h2 id="toc_0">Lucene</h2>

<p>Lucene是一个代码库，使用Java开发的搜索引擎，不利于分布式拓展。</p>

<h2 id="toc_1">Solr</h2>

<p>Slor是基于Lucene开发的搜索引擎，是apache开源的搜索引擎，只支持Java。</p>

<h2 id="toc_2">Elasticsearch</h2>

<p>ES也是基于Lucene开发，支持分布式，以及多种语言，拓展性比较好。支持TB级别的搜索（TB级别是1024T容量查询）。<br/>
ES是基于文档去检索的。</p>

<h3 id="toc_3">ES核心术语</h3>

<ul>
<li>索引 Index
<ul>
<li>相当于数据库的表</li>
</ul></li>
<li>类型 type
<ul>
<li>相当于表的逻辑类型，用于区分索引，ES 7.x已经不在使用了，老得版本还在使用</li>
</ul></li>
<li>文档 document
<ul>
<li>相当于行，是json的形式去存在的</li>
</ul></li>
<li>字段 fields
<ul>
<li>列 </li>
</ul></li>
<li>映射 mapping
<ul>
<li>相当于表结构定义</li>
</ul></li>
<li>近实时 NRT
<ul>
<li>Near real time 接近真实的时间，当新建一个文档之后，一般会有1秒左右的时间的延时</li>
</ul></li>
<li>节点 node
<ul>
<li>每一个服务器，就是一个节点</li>
</ul></li>
<li>shard replica
<ul>
<li>数据分片与备份</li>
</ul></li>
</ul>

<h4 id="toc_4">集群相关</h4>

<p><img src="media/16076110407363/ES%E6%9E%B6%E6%9E%84%E7%89%B9%E7%82%B9.png" alt="ES架构特点"/></p>

<p>分片（shard）：把索引库拆分为多份，分别放在不同的节点上，比如有3个节点，3个节点的所有数据内容加在一起是一个完整的索引库，分别保存到三个节点上，目的为了水平拓展，提高吞吐量。<br/>
备份（replica）：每个shard的备份。</p>

<h4 id="toc_5">简称</h4>

<p>shard = primary shard（主分片）<br/>
replica = replica shard（备份节点）</p>

<h4 id="toc_6">倒排索引</h4>

<p>倒排索引就是将正排索引的文档内容进行分词，然后记录这个词在每个文档出现的文档ID。<br/>
<img src="media/16076110407363/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95.png" alt="倒排索引"/><br/>
词频TF：位置POS<br/>
词频是记录这个词在那个文档下出现的次数和位置，记录方法：1:1:<1>，表示文档ID1下，出现过1次，在下标为1的位置。<br/>
<img src="media/16076110407363/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95%E8%AF%8D%E9%A2%91.png" alt="倒排索引词频"/></p>

<blockquote>
<p>倒排索引源于实际应用中需要根据属性的值来查找记录。这种索引表中的每一项都包括u一个属性值和包含该属性的各个记录地址。由于不是根据记录来确定属性，而是根据属性来确定记录的位置，所以称之为倒排索引。</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SpringBoot使用模版]]></title>
    <link href="jythons.github.io/16073547198404.html"/>
    <updated>2020-12-07T23:25:19+08:00</updated>
    <id>jythons.github.io/16073547198404.html</id>
    <content type="html"><![CDATA[
<p>SpringBoot使用html模版，Controller需要使用注解：@Controller</p>

<h2 id="toc_0">pom配置</h2>

<pre><code class="language-text">&lt;dependency&gt;
      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
      &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>

<h2 id="toc_1">yml配置</h2>

<pre><code class="language-text">spring:
    thymeleaf:
    mode: HTML
    encoding: UTF-8
    prefix: classpath:/templates/
    suffix: .html
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SpringBoot会话拦截器]]></title>
    <link href="jythons.github.io/16073519255991.html"/>
    <updated>2020-12-07T22:38:45+08:00</updated>
    <id>jythons.github.io/16073519255991.html</id>
    <content type="html"><![CDATA[
<p>会话拦截器，用于在请求一些接口之前，统一去拦截请求，进行验证等操作。</p>

<span id="more"></span><!-- more -->

<pre><code class="language-text">package com.sample.controller.interceptor;
import org.springframework.web.servlet.HandlerInterceptor;

public class UserTokenInterceptor implements HandlerInterceptor {
    
    /**
     * 拦截请求，在访问controller调用之前
     * @param request
     * @param response
     * @param handler
     * @return
     * @throws Exception
     */
    @Override
    public boolean preHandle(HttpServletRequest request, 
                             HttpServletResponse response,
                             Object handler){
         
    }
    
    /**
     * 请求访问controller之后，渲染视图之前
     * @param request
     * @param response
     * @param handler
     * @param modelAndView
     * @throws Exception
     */
    @Override
    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception {

    }

    /**
     * 请求访问controller之后，渲染视图之后
     * @param request
     * @param response
     * @param handler
     * @param ex
     * @throws Exception
     */
    @Override
    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception {

    }
}
</code></pre>

<blockquote>
<p>以上配置好之后，还需要将拦截器注册一下才可使用。</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SpringSession yml配置]]></title>
    <link href="jythons.github.io/16073500415348.html"/>
    <updated>2020-12-07T22:07:21+08:00</updated>
    <id>jythons.github.io/16073500415348.html</id>
    <content type="html"><![CDATA[
<p>使用SpringSession，需要先引入依赖，查看Maven Dependency Spring Session, 目前都是使用分布式的方式部署，因此使用redis会好一点。</p>

<h2 id="toc_0">Application配置</h2>

<pre><code class="language-text">spring:
    session:
        store-type: redis
</code></pre>

<h2 id="toc_1">配置启动</h2>

<p>在启动类里面配置启动</p>

<pre><code class="language-text">// 开启使用redis作为Spring Session
@EnableRedisHttpSession
</code></pre>

<h2 id="toc_2">使用方法</h2>

<pre><code class="language-text">public Object setSession(HttpServletRequest request) {
    HttpSession session = request.getSession();
    session.setAttribute(&quot;userInfo&quot;, &quot;XXX&quot;);
    session.setMaxInactiveInterval(3600);
    session.getAttribute(&quot;userInfo);
    session.removeAttribute(&quot;userInfo&quot;);
}
</code></pre>

<blockquote>
<p>因为使用Spring Session，需要安装Spring安全框架依赖，因为安装了这个依赖后，程序每次访问都需要登录，很麻烦，因此在启动类将它排除即可。排除方法见下方：</p>
</blockquote>

<pre><code class="language-text">@SpringBootApplication(exclude = {SecurityAutoConfiguration.class})
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Maven Dependency]]></title>
    <link href="jythons.github.io/16073491976884.html"/>
    <updated>2020-12-07T21:53:17+08:00</updated>
    <id>jythons.github.io/16073491976884.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<pre><code class="language-text">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;
    &lt;exclusions&gt;
        &lt;exclusion&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;
        &lt;/exclusion&gt;
    &lt;/exclusions&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
    &lt;!-- 打包war [2] 移除自带内置tomcat --&gt;
    &lt;exclusions&gt;
        &lt;exclusion&gt;
            &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;/exclusion&gt;
    &lt;/exclusions&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;
    &lt;optional&gt;true&lt;/optional&gt;
&lt;/dependency&gt;
        
&lt;!-- redis --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
&lt;/dependency&gt;

&lt;!-- SpringSession --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.session&lt;/groupId&gt;
    &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;
&lt;/dependency&gt;

&lt;!-- Spring 安全框架 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;
&lt;/dependency&gt;

&lt;!-- apache 工具类 --&gt;
&lt;dependency&gt;
      &lt;groupId&gt;commons-codec&lt;/groupId&gt;
      &lt;artifactId&gt;commons-codec&lt;/artifactId&gt;
      &lt;version&gt;1.11&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
      &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
      &lt;artifactId&gt;commons-lang3&lt;/artifactId&gt;
      &lt;version&gt;3.4&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
      &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
      &lt;artifactId&gt;commons-io&lt;/artifactId&gt;
      &lt;version&gt;1.3.2&lt;/version&gt;
&lt;/dependency&gt;

&lt;!-- mysql驱动 --&gt;
&lt;dependency&gt;
      &lt;groupId&gt;mysql&lt;/groupId&gt;
      &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
      &lt;version&gt;5.1.41&lt;/version&gt;
&lt;/dependency&gt;

&lt;!-- mybatis --&gt;
&lt;dependency&gt;
      &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt;
      &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt;
      &lt;version&gt;2.1.0&lt;/version&gt;
&lt;/dependency&gt;

&lt;!-- 通用mapper逆向工具 --&gt;
&lt;dependency&gt;
      &lt;groupId&gt;tk.mybatis&lt;/groupId&gt;
      &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt;
      &lt;version&gt;2.1.5&lt;/version&gt;
&lt;/dependency&gt;

&lt;!--pagehelper --&gt;
&lt;dependency&gt;
      &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt;
      &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt;
      &lt;version&gt;1.2.12&lt;/version&gt;
&lt;/dependency&gt;

&lt;!--引入日志依赖 抽象层 与 实现层--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
    &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;
    &lt;version&gt;1.7.21&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.slf4j&lt;/groupId&gt;
    &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;
    &lt;version&gt;1.7.21&lt;/version&gt;
&lt;/dependency&gt;

&lt;!-- 打包war [3] 添加依赖 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;javax.servlet&lt;/groupId&gt;
    &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt;
    &lt;scope&gt;provided&lt;/scope&gt;
&lt;/dependency&gt;

&lt;!-- html模版 --&gt;
&lt;dependency&gt;
      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
      &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[缓存雪崩预防]]></title>
    <link href="jythons.github.io/16068348833531.html"/>
    <updated>2020-12-01T23:01:23+08:00</updated>
    <id>jythons.github.io/16068348833531.html</id>
    <content type="html"><![CDATA[
<p>当缓存大面积失效，请求会全部打到数据库上，这种情况就是雪崩。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">预防方法</h2>

<ul>
<li>设置缓存用不过期</li>
<li>过期时间错开</li>
<li>多级缓存</li>
<li>采购第三方Redis</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SpringBoot集成Redis集群]]></title>
    <link href="jythons.github.io/16067500364861.html"/>
    <updated>2020-11-30T23:27:16+08:00</updated>
    <id>jythons.github.io/16067500364861.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<h2 id="toc_0">使用集群的配置</h2>

<pre><code class="language-text">spring:
    redis:
        password: mima
        cluster:
            nodes: 192.168.1.201:6379,192.168.1.202:6379,192.168.1.203:6379,192.168.1.204:6379,192.168.1.205:6379,192.168.1.206:6379,
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis-Cluster集群]]></title>
    <link href="jythons.github.io/16067481675978.html"/>
    <updated>2020-11-30T22:56:07+08:00</updated>
    <id>jythons.github.io/16067481675978.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">集群配置</h2>

<p>打开redis配置文件，找到 REDIS CLUSTER 配置块。修改以下配置：</p>

<pre><code class="language-text"># 开启redis-cluster集群配置
cluster-enabled yes
# 每一个节点在集群中的配置文件, 该文件有redis自己去维护 
cluster-config-file nodes-6379.conf
# 超时时间，超时自动切换
cluster-node-timeout 5000
# aof模式
appendonly yes
# aof日志文件名
appendfilename &quot;appendonly.aof&quot;
</code></pre>

<blockquote>
<p>构建集群时，需要将.rdb文件和.aof文件删除或者清空，否则会报错。</p>
</blockquote>

<span id="more"></span><!-- more -->

<h2 id="toc_1">构建集群</h2>

<blockquote>
<p>早期，构建redis集群使用的是ruby去构建的，在redis源码目录下，进入到src目录，下面有一个.rb的ruby脚本，通过这个脚本来构建集群，新版本不在使用这个方式。</p>
</blockquote>

<p>新版本构建方法</p>

<pre><code class="language-text">redis-cli --cluster help 回车，可以查看命令使用方法

# create 后面的地址是集群所有节点的地址，--cluster-replicas表示slave节点和master节点的比值，1就是1个master对应1个slave
redis-cli --cluster create 192.168.1.201:6379 192.168.1.202:6379 192.168.1.203:6379 192.168.1.204:6379 192.168.1.205:6379 192.168.1.206:6379 --cluster-replicas 1
</code></pre>

<blockquote>
<p>创建集群时，如果报错没有权限，在命令开头加上：-a 密码，即可</p>
</blockquote>

<p>检查集群是否创建成功</p>

<pre><code class="language-text">redis-cli --cluster 192.168.1.201:6379 
# 会输出集群各个节点信息
</code></pre>

<h2 id="toc_2">slot槽节点</h2>

<p>槽节点是在master节点上平均分配的，slave节点是没有槽节点的，数据就是保存在这个槽位里面的。<br/>
<img src="media/16067481675978/slot%E8%8A%82%E7%82%B9.png" alt="slot节点"/></p>

<h3 id="toc_3">槽slot怎么存储</h3>

<p>当我们存储一个key的时候，redis会根据这个key去hash一个值，然后取余槽节点总数，计算出来的值就是这个槽位的位置。<br/>
<img src="media/16067481675978/slot%E5%AD%98%E5%82%A8.png" alt="slot存储"/></p>

<blockquote>
<p>查看集群信息，cluster info<br/>
查看节点信息，cluster nodes</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SpringBoot集成Redis哨兵]]></title>
    <link href="jythons.github.io/16067477234035.html"/>
    <updated>2020-11-30T22:48:43+08:00</updated>
    <id>jythons.github.io/16067477234035.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<h2 id="toc_0">哨兵模式配置</h2>

<pre><code class="language-text">spring:
    redis:
        database: 1
        password: imooc
        sentinel:
            master: master-redis # master节点名称
            nodes： 192.168.1.191:26379,192.168.1.191:26379,192.168.1.191:26379 # 哨兵节点地址
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis哨兵机制与实现]]></title>
    <link href="jythons.github.io/16062286652893.html"/>
    <updated>2020-11-24T22:37:45+08:00</updated>
    <id>jythons.github.io/16062286652893.html</id>
    <content type="html"><![CDATA[
<p>Redis使用源码安装的，在源码包内有一个 sentinel.conf 文件，这个文件就是哨兵机制的配置文件，将该配置文件拷贝到 /usr/local/redis 目录下。然后编辑配置即可。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">sentinel.conf配置</h2>

<pre><code class="language-text"># 绑定一个IP，如果redis需要暴漏在公网下，就需要绑定一个IP地址，
bind 127.0.0.1 192.168.1.1

# 是否开启保护模式, 默认：no 不开启，保证所有节点都可以访问
protected-mode no

# 端口号
port 26379

# 是否在后台启用
daemonize yes

# 哨兵的进程
pidfile /var/run/redis-sentinel.pid

# 日志文件
logfile /usr/local/redis/sentinel/redis-sentinel.log

# 工作目录
dir /usr/local/redis/sentinel

# 哨兵机制的核心配置：mymaster 相当于redis master节点的名称
# 后面的IP 端口是master节点的地址和端口，
# 最后面的2，表示多少个哨兵ping不通master，就可以决定这个节点挂掉了，
# 然后就可以故障转移了
sentinel monitor mymaster 127.0.0.1 6379 2

# 配置密码
sentinel auth-pass mymaster password

# 配置多少毫秒内断定节点属于宕机
sentinel down-after-milliseconds mymaster 30000

# 如果master挂掉之后，需要选举出一个slave节点作为master，这时其他的只节点需要和这个新的master节点同步数据，这个配置表示同步时的并行个数
sentinel parallel-syncs mymaster 1

# 发生故障时，需要做故障转移，如果某个哨兵在3分钟内（180000ms）没有操作，则由其他哨兵来完成转移
sentinel failover-timeout mymaster 180000
</code></pre>

<h2 id="toc_1">哨兵模式启动</h2>

<pre><code class="language-text">redis-sentinel /usr/local/redis/sentinel.conf
</code></pre>

<blockquote>
<p>当原来挂掉的主节点恢复了以后，他会自动变为slave节点，不在是master节点。</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 缓存过期机制]]></title>
    <link href="jythons.github.io/16061468058717.html"/>
    <updated>2020-11-23T23:53:25+08:00</updated>
    <id>jythons.github.io/16061468058717.html</id>
    <content type="html"><![CDATA[
<ul>
<li>（主动）定期删除</li>
<li>（被动）惰性删除</li>
</ul>

<span id="more"></span><!-- more -->

<h2 id="toc_0">定期删除</h2>

<p>定期删除就是redis会定期去抽查缓存是否过期，默认1秒钟10次（可自己配置），如果过期就会自动删除，删除后就不可访问。</p>

<pre><code class="language-text"># redis.conf
# 设置自动检查数量
hz 10
</code></pre>

<h2 id="toc_1">惰性删除</h2>

<p>惰性删除是指客户端请求的时候，可能会请求到一个过期的key，这时redis会去检查这个key是否过期，如果过期就会删除，这种策略对CPU比较友好，不会占用过多的CPU，缺点就是内存会被一直占用。</p>

<blockquote>
<p>以上两种策略只针对设置了过期时间的key生效。</p>
</blockquote>

<h2 id="toc_2">内存淘汰管理机制</h2>

<p>计算机的内存是有限的，redis自身带有内存管理机制（memory management）。<br/>
可以在配置文件内设置一个阀值（maxmemory），如果超过了这个阀值，redis会自动去清理，会清理那些没有设置过期时间的数据。</p>

<ul>
<li>noeviction (默认)
<ul>
<li>内存满了之后不允许继续写入</li>
</ul></li>
<li>volatile-lru
<ul>
<li>针对时间，选择时间最少的去清理</li>
</ul></li>
<li>allkeys-lru
<ul>
<li>针对时间选择key去清理，任何key都有可能被清理掉</li>
</ul></li>
<li>volatile-lfu
<ul>
<li>针对设置过缓存时间的，在这些缓存里面清理较少使用的数据</li>
</ul></li>
<li>allkeys-lfu （推荐）
<ul>
<li>当内存满了之后，有新的key需要写入时，他会清理那些不经常使用的缓存清理掉</li>
</ul></li>
<li>volatile-random
<ul>
<li>针对设置了过期时间的缓存，随机清理掉，任何key 都可能删除</li>
</ul></li>
<li>allkeys-random
<ul>
<li>随机删除，任何的key都有可能删除掉</li>
</ul></li>
<li>volatile-ttl
<ul>
<li>设置了过期时间的，即将要过期的优先淘汰</li>
</ul></li>
</ul>

<blockquote>
<p>LRU 针对时间的，使用最少<br/>
LFU 针对动作的，使用最少</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 主从复制原理]]></title>
    <link href="jythons.github.io/16057135385527.html"/>
    <updated>2020-11-18T23:32:18+08:00</updated>
    <id>jythons.github.io/16057135385527.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">主从架构</h2>

<p>单机单个节点，redis并发支持上万，但是随着业务的复杂度，redis的并发度还是会有上限的。因此还是需要在架构上进行优化。 <br/>
主从架构是一种水平横向拓展的架构，读写分离。 主节点负责数据的写入，从节点负责读操作。<br/>
<img src="media/16057135385527/redis%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84.png" alt="redis主从架构"/></p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">主从原理</h2>

<p>当主节点和从节点启动后，在从节点会有一些相关的配置，启动后，从节点会对主节点发出ping请求，这时主节点会将全量数据复制给从节点，也就是复制RDB。<br/>
主节点会将内存里面的数据备份一个RDB文件，然后将RDB文件复制给从节点，从节点拿到主节点传过来的RDB文件后，将RDB文件的内容加载到从节点的内存当中。这是一个初始化的过程，当以后主节点有数据写入时，主节点会把命令发送给从节点，从节点将数据写入到内存。<br/>
<img src="media/16057135385527/redis%E4%B8%BB%E4%BB%8E%E5%8E%9F%E7%90%86.png" alt="redis主从原理"/><br/>
当从节点下线一段时间后，再次恢复时，主节点会把下线这段时间的增量数据，一起同步给从节点。<br/>
如果要使用主从的话，主节点必须开启持久化，<strong>如果主节点没有开启持久化，当主节点宕机后，再次上线之后，主节点会将从节点的数据清空</strong>。</p>

<h2 id="toc_2">主从模式</h2>

<p>redis主从模式，一般都是一主2从，从节点不会太多，因为主从复制其实就是文件的上传和下载，如果从节点太多，主从复制的时候会占用很大一部分内网的带宽。<br/>
如果需要多个从节点，可以在从节点上继续配置主从模式，也就是从节点下还有从节点。<br/>
<img src="media/16057135385527/redis%E4%B8%BB%E4%BB%8E%E6%A8%A1%E5%BC%8F.png" alt="redis主从模式"/></p>

<h2 id="toc_3">主从实践</h2>

<blockquote>
<p>在redis客户端，使用：info replication 命令，查看当前redis节点的主从配置信息。</p>
</blockquote>

<p>在redis.conf配置文件搜索 REPLICATION 找到配置主从的位置。配置主从时，只需要配置从节点即可，无需配置主节点。</p>

<h3 id="toc_4">配置从节点</h3>

<pre><code class="language-text"># 配置主节点的ip和端口
replicaof &lt;masterip&gt; &lt;masterport&gt;

# 配置主节点的登录密码（主节点没有配置密码，不需要配置该选项）
masterauth &lt;master-password&gt;

# 配置，只要是从节点，都开启，表示从节点只读，不进行写操作
replica-read-only yes
</code></pre>

<h3 id="toc_5">无磁盘化复制</h3>

<p>redis主从复制，默认是从节点将主节点保存在磁盘的rdb文件复制到从节点的磁盘，然后在将rdb文件恢复到内存。<br/>
无磁盘化复制，是将主节点的数据从主节点的内存中直接读取并写入从节点的内存，这样的传输方式，是使用socket的方式进行传输。<br/>
<img src="media/16057135385527/redis%E6%97%A0%E7%A3%81%E7%9B%98%E5%8C%96%E5%A4%8D%E5%88%B6.png" alt="redis无磁盘化复制"/></p>

<pre><code class="language-text"># 数据同步策略：无磁盘化复制，yes 开启，no 关闭
# 目前数据测试阶段，生产环境不建议使用 
repl-diskless-sync no
</code></pre>

<blockquote>
<p>redis数据同步策略有两种，一种是磁盘同步，也是默认的同步方式，redis新建一个进程，将数据写入rdb文件，这些rdb文件会定期向slave节点的磁盘同步。另一种数据同步的策略就是无磁盘化同步，master会创建一个新的进程，这个进程会向socket写入rdb文件，不向磁盘写入。如果服务器网络吞吐量比较大，可以使用第二种方式，提高效率。</p>
</blockquote>

<p>master节点可以配置一个时间，定期的向socket写入rdb文件。</p>

<pre><code class="language-text"># 无磁盘化同步间隔时间，单位（秒）
repl-diskless-sync-delay 5
</code></pre>

]]></content>
  </entry>
  
</feed>
