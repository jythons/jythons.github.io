<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Jythons小站]]></title>
  <link href="jythons.github.io/atom.xml" rel="self"/>
  <link href="jythons.github.io/"/>
  <updated>2020-11-19T00:01:08+08:00</updated>
  <id>jythons.github.io/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.coderforart.com/">CoderForArt</generator>

  
  <entry>
    <title type="html"><![CDATA[SpringBoot集成Redis集群]]></title>
    <link href="jythons.github.io/16067500364861.html"/>
    <updated>2020-11-30T23:27:16+08:00</updated>
    <id>jythons.github.io/16067500364861.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<h2 id="toc_0">使用集群的配置</h2>

<pre><code class="language-text">spring:
    redis:
        password: mima
        cluster:
            nodes: 192.168.1.201:6379,192.168.1.202:6379,192.168.1.203:6379,192.168.1.204:6379,192.168.1.205:6379,192.168.1.206:6379,
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis-Cluster集群]]></title>
    <link href="jythons.github.io/16067481675978.html"/>
    <updated>2020-11-30T22:56:07+08:00</updated>
    <id>jythons.github.io/16067481675978.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">集群配置</h2>

<p>打开redis配置文件，找到 REDIS CLUSTER 配置块。修改以下配置：</p>

<pre><code class="language-text"># 开启redis-cluster集群配置
cluster-enabled yes
# 每一个节点在集群中的配置文件, 该文件有redis自己去维护 
cluster-config-file nodes-6379.conf
# 超时时间，超时自动切换
cluster-node-timeout 5000
# aof模式
appendonly yes
# aof日志文件名
appendfilename &quot;appendonly.aof&quot;
</code></pre>

<blockquote>
<p>构建集群时，需要将.rdb文件和.aof文件删除或者清空，否则会报错。</p>
</blockquote>

<span id="more"></span><!-- more -->

<h2 id="toc_1">构建集群</h2>

<blockquote>
<p>早期，构建redis集群使用的是ruby去构建的，在redis源码目录下，进入到src目录，下面有一个.rb的ruby脚本，通过这个脚本来构建集群，新版本不在使用这个方式。</p>
</blockquote>

<p>新版本构建方法</p>

<pre><code class="language-text">redis-cli --cluster help 回车，可以查看命令使用方法

# create 后面的地址是集群所有节点的地址，--cluster-replicas表示slave节点和master节点的比值，1就是1个master对应1个slave
redis-cli --cluster create 192.168.1.201:6379 192.168.1.202:6379 192.168.1.203:6379 192.168.1.204:6379 192.168.1.205:6379 192.168.1.206:6379 --cluster-replicas 1
</code></pre>

<blockquote>
<p>创建集群时，如果报错没有权限，在命令开头加上：-a 密码，即可</p>
</blockquote>

<p>检查集群是否创建成功</p>

<pre><code class="language-text">redis-cli --cluster 192.168.1.201:6379 
# 会输出集群各个节点信息
</code></pre>

<h2 id="toc_2">slot槽节点</h2>

<p>槽节点是在master节点上平均分配的，slave节点是没有槽节点的，数据就是保存在这个槽位里面的。<br/>
<img src="media/16067481675978/slot%E8%8A%82%E7%82%B9.png" alt="slot节点"/></p>

<h3 id="toc_3">槽slot怎么存储</h3>

<p>当我们存储一个key的时候，redis会根据这个key去hash一个值，然后取余槽节点总数，计算出来的值就是这个槽位的位置。<br/>
<img src="media/16067481675978/slot%E5%AD%98%E5%82%A8.png" alt="slot存储"/></p>

<blockquote>
<p>查看集群信息，cluster info<br/>
查看节点信息，cluster nodes</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SpringBoot集成Redis哨兵]]></title>
    <link href="jythons.github.io/16067477234035.html"/>
    <updated>2020-11-30T22:48:43+08:00</updated>
    <id>jythons.github.io/16067477234035.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<h2 id="toc_0">哨兵模式配置</h2>

<pre><code class="language-text">spring:
    redis:
        database: 1
        password: imooc
        sentinel:
            master: master-redis # master节点名称
            nodes： 192.168.1.191:26379,192.168.1.191:26379,192.168.1.191:26379 # 哨兵节点地址
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis哨兵机制与实现]]></title>
    <link href="jythons.github.io/16062286652893.html"/>
    <updated>2020-11-24T22:37:45+08:00</updated>
    <id>jythons.github.io/16062286652893.html</id>
    <content type="html"><![CDATA[
<p>Redis使用源码安装的，在源码包内有一个 sentinel.conf 文件，这个文件就是哨兵机制的配置文件，将该配置文件拷贝到 /usr/local/redis 目录下。然后编辑配置即可。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">sentinel.conf配置</h2>

<pre><code class="language-text"># 绑定一个IP，如果redis需要暴漏在公网下，就需要绑定一个IP地址，
bind 127.0.0.1 192.168.1.1

# 是否开启保护模式, 默认：no 不开启，保证所有节点都可以访问
protected-mode no

# 端口号
port 26379

# 是否在后台启用
daemonize yes

# 哨兵的进程
pidfile /var/run/redis-sentinel.pid

# 日志文件
logfile /usr/local/redis/sentinel/redis-sentinel.log

# 工作目录
dir /usr/local/redis/sentinel

# 哨兵机制的核心配置：mymaster 相当于redis master节点的名称
# 后面的IP 端口是master节点的地址和端口，
# 最后面的2，表示多少个哨兵ping不通master，就可以决定这个节点挂掉了，
# 然后就可以故障转移了
sentinel monitor mymaster 127.0.0.1 6379 2

# 配置密码
sentinel auth-pass mymaster password

# 配置多少毫秒内断定节点属于宕机
sentinel down-after-milliseconds mymaster 30000

# 如果master挂掉之后，需要选举出一个slave节点作为master，这时其他的只节点需要和这个新的master节点同步数据，这个配置表示同步时的并行个数
sentinel parallel-syncs mymaster 1

# 发生故障时，需要做故障转移，如果某个哨兵在3分钟内（180000ms）没有操作，则由其他哨兵来完成转移
sentinel failover-timeout mymaster 180000
</code></pre>

<h2 id="toc_1">哨兵模式启动</h2>

<pre><code class="language-text">redis-sentinel /usr/local/redis/sentinel.conf
</code></pre>

<blockquote>
<p>当原来挂掉的主节点恢复了以后，他会自动变为slave节点，不在是master节点。</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 缓存过期机制]]></title>
    <link href="jythons.github.io/16061468058717.html"/>
    <updated>2020-11-23T23:53:25+08:00</updated>
    <id>jythons.github.io/16061468058717.html</id>
    <content type="html"><![CDATA[
<ul>
<li>（主动）定期删除</li>
<li>（被动）惰性删除</li>
</ul>

<span id="more"></span><!-- more -->

<h2 id="toc_0">定期删除</h2>

<p>定期删除就是redis会定期去抽查缓存是否过期，默认1秒钟10次（可自己配置），如果过期就会自动删除，删除后就不可访问。</p>

<pre><code class="language-text"># redis.conf
# 设置自动检查数量
hz 10
</code></pre>

<h2 id="toc_1">惰性删除</h2>

<p>惰性删除是指客户端请求的时候，可能会请求到一个过期的key，这时redis会去检查这个key是否过期，如果过期就会删除，这种策略对CPU比较友好，不会占用过多的CPU，缺点就是内存会被一直占用。</p>

<blockquote>
<p>以上两种策略只针对设置了过期时间的key生效。</p>
</blockquote>

<h2 id="toc_2">内存淘汰管理机制</h2>

<p>计算机的内存是有限的，redis自身带有内存管理机制（memory management）。<br/>
可以在配置文件内设置一个阀值（maxmemory），如果超过了这个阀值，redis会自动去清理，会清理那些没有设置过期时间的数据。</p>

<ul>
<li>noeviction (默认)
<ul>
<li>内存满了之后不允许继续写入</li>
</ul></li>
<li>volatile-lru
<ul>
<li>针对时间，选择时间最少的去清理</li>
</ul></li>
<li>allkeys-lru
<ul>
<li>针对时间选择key去清理，任何key都有可能被清理掉</li>
</ul></li>
<li>volatile-lfu
<ul>
<li>针对设置过缓存时间的，在这些缓存里面清理较少使用的数据</li>
</ul></li>
<li>allkeys-lfu （推荐）
<ul>
<li>当内存满了之后，有新的key需要写入时，他会清理那些不经常使用的缓存清理掉</li>
</ul></li>
<li>volatile-random
<ul>
<li>针对设置了过期时间的缓存，随机清理掉，任何key 都可能删除</li>
</ul></li>
<li>allkeys-random
<ul>
<li>随机删除，任何的key都有可能删除掉</li>
</ul></li>
<li>volatile-ttl
<ul>
<li>设置了过期时间的，即将要过期的优先淘汰</li>
</ul></li>
</ul>

<blockquote>
<p>LRU 针对时间的，使用最少<br/>
LFU 针对动作的，使用最少</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis 主从复制原理]]></title>
    <link href="jythons.github.io/16057135385527.html"/>
    <updated>2020-11-18T23:32:18+08:00</updated>
    <id>jythons.github.io/16057135385527.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">主从架构</h2>

<p>单机单个节点，redis并发支持上万，但是随着业务的复杂度，redis的并发度还是会有上限的。因此还是需要在架构上进行优化。 <br/>
主从架构是一种水平横向拓展的架构，读写分离。 主节点负责数据的写入，从节点负责读操作。<br/>
<img src="media/16057135385527/redis%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84.png" alt="redis主从架构"/></p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">主从原理</h2>

<p>当主节点和从节点启动后，在从节点会有一些相关的配置，启动后，从节点会对主节点发出ping请求，这时主节点会将全量数据复制给从节点，也就是复制RDB。<br/>
主节点会将内存里面的数据备份一个RDB文件，然后将RDB文件复制给从节点，从节点拿到主节点传过来的RDB文件后，将RDB文件的内容加载到从节点的内存当中。这是一个初始化的过程，当以后主节点有数据写入时，主节点会把命令发送给从节点，从节点将数据写入到内存。<br/>
<img src="media/16057135385527/redis%E4%B8%BB%E4%BB%8E%E5%8E%9F%E7%90%86.png" alt="redis主从原理"/><br/>
当从节点下线一段时间后，再次恢复时，主节点会把下线这段时间的增量数据，一起同步给从节点。<br/>
如果要使用主从的话，主节点必须开启持久化，<strong>如果主节点没有开启持久化，当主节点宕机后，再次上线之后，主节点会将从节点的数据清空</strong>。</p>

<h2 id="toc_2">主从模式</h2>

<p>redis主从模式，一般都是一主2从，从节点不会太多，因为主从复制其实就是文件的上传和下载，如果从节点太多，主从复制的时候会占用很大一部分内网的带宽。<br/>
如果需要多个从节点，可以在从节点上继续配置主从模式，也就是从节点下还有从节点。<br/>
<img src="media/16057135385527/redis%E4%B8%BB%E4%BB%8E%E6%A8%A1%E5%BC%8F.png" alt="redis主从模式"/></p>

<h2 id="toc_3">主从实践</h2>

<blockquote>
<p>在redis客户端，使用：info replication 命令，查看当前redis节点的主从配置信息。</p>
</blockquote>

<p>在redis.conf配置文件搜索 REPLICATION 找到配置主从的位置。配置主从时，只需要配置从节点即可，无需配置主节点。</p>

<h3 id="toc_4">配置从节点</h3>

<pre><code class="language-text"># 配置主节点的ip和端口
replicaof &lt;masterip&gt; &lt;masterport&gt;

# 配置主节点的登录密码（主节点没有配置密码，不需要配置该选项）
masterauth &lt;master-password&gt;

# 配置，只要是从节点，都开启，表示从节点只读，不进行写操作
replica-read-only yes
</code></pre>

<h3 id="toc_5">无磁盘化复制</h3>

<p>redis主从复制，默认是从节点将主节点保存在磁盘的rdb文件复制到从节点的磁盘，然后在将rdb文件恢复到内存。<br/>
无磁盘化复制，是将主节点的数据从主节点的内存中直接读取并写入从节点的内存，这样的传输方式，是使用socket的方式进行传输。<br/>
<img src="media/16057135385527/redis%E6%97%A0%E7%A3%81%E7%9B%98%E5%8C%96%E5%A4%8D%E5%88%B6.png" alt="redis无磁盘化复制"/></p>

<pre><code class="language-text"># 数据同步策略：无磁盘化复制，yes 开启，no 关闭
# 目前数据测试阶段，生产环境不建议使用 
repl-diskless-sync no
</code></pre>

<blockquote>
<p>redis数据同步策略有两种，一种是磁盘同步，也是默认的同步方式，redis新建一个进程，将数据写入rdb文件，这些rdb文件会定期向slave节点的磁盘同步。另一种数据同步的策略就是无磁盘化同步，master会创建一个新的进程，这个进程会向socket写入rdb文件，不向磁盘写入。如果服务器网络吞吐量比较大，可以使用第二种方式，提高效率。</p>
</blockquote>

<p>master节点可以配置一个时间，定期的向socket写入rdb文件。</p>

<pre><code class="language-text"># 无磁盘化同步间隔时间，单位（秒）
repl-diskless-sync-delay 5
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis的持久化机制]]></title>
    <link href="jythons.github.io/16056250808598.html"/>
    <updated>2020-11-17T22:58:00+08:00</updated>
    <id>jythons.github.io/16056250808598.html</id>
    <content type="html"><![CDATA[
<p>Redis的数据是存放在缓存里面的，当计算机重启后，缓存内的数据会被清除，这时数据就会消失，因此，redis是可以支持持久化的，他可以根据策略将缓存中的数据存放到硬盘当中，保证数据的持久性。<br/>
Reids的持久化有两种方式，一种是RDB，另一种是AOF。下面分别介绍一下两种持久化机制的使用。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">RDB（Redis Database）</h2>

<p>RDB模式，是每隔一段时间以快照的方式去备份内存中的数据备份到磁盘上。备份的数据是开始备份那个时间点前的数据。</p>

<h3 id="toc_1">RDB优势</h3>

<ul>
<li>以单独的文件的形式去备份，他可以设置每个小时或者每天去备份一次，恢复的时候，可以根据不同的版本去恢复数据到内存当中。</li>
<li>方便灾后恢复数据，因为它只有一个文件，这个问价中的内容是完整的。</li>
<li>备份时，他是以子进程的方式进行备份的，没有占用主进程，保证服务可以正常运行。当子进程进行备份时，主进程不会进行磁盘的IO，这样可以保证数据的完整性。（？这时如果有数据进来怎么做）</li>
<li>当进行数据恢复的时候，可以快速的恢复比较大的数据集，相对于AOF，恢复的速度更快。</li>
</ul>

<h3 id="toc_2">RDB劣势</h3>

<ul>
<li>RDB是每隔一段时间去备份一次，当在备份的间隔时间内出现宕机，这时，在上次备份的时间点到宕机这个时间点之间的数据会丢失。如果不在乎数据的完整性，可以使用。</li>
<li>RDB在备份的时候，是fork一个子进程进行执行备份操作，这个子进程和主进程是相同的，如果数据集比较大，复制数据时，对于计算机的CPU消耗会比较大。</li>
<li>不能做到实时的备份。</li>
</ul>

<h3 id="toc_3">RDB配置</h3>

<p>打开Redis的配置文件 redis.conf，搜索SNAPSHOTTING，找到dir，这个就是备份时保存的文件路径。</p>

<pre><code class="language-text"># 如果至少有一个key发生变化，在900秒后就会保存一次快照
save 900 1
# 如果至少有10个key发生变化，那么在300秒后就回保存一次快照
save 300 10
# 如果至少有10000个key发生了变化，在60秒后就回保存一次快照
save 60 10000

# 如果保存的时候发生错误，就停止写入操作, 如果发生错误不停止写操作，就回出现数据
# 不一致的情况。
stop-writes-on-bgsave-error yes

# 这个是指是否使用压缩，如果使用压缩会占用CPU的性能，如果不使用压缩可以设置为no
# 使用 LZF 方式去压缩
rdbcompression yes

# 数据校验，使用CRC64去校验，使用校验，会有10%的性能消耗
rdbchecksum yes

# 备份文件名称
dbfilename dump.rdb
# 备份文件路径
dir /usr/local/redis/working
</code></pre>

<blockquote>
<p>总结：使用RDB的备份方式，比较适合大数据量的恢复操作，但是如果在最后一次保存之前出现异常，这时就回丢失数据，对数据的完整性没有保障，如果不在乎数据的完整性，可以使用RDB的持久化方式。</p>
</blockquote>

<h2 id="toc_4">AOF（append only fashion）</h2>

<p>aof是以日志的形式存在，只要数据发生变更，就会以追加的方式写入日志，由于aof的日志会越写越大，所以可以通过配置的方式去将日志进行切割。</p>

<h3 id="toc_5">AOF 优势</h3>

<ul>
<li>使用AOF可以使redis持久化更加健壮，他有三种方式去触发持久化
<ul>
<li>在关闭时触发</li>
<li>每秒触发（默认的方式）</li>
<li>发生写操作时触发</li>
</ul></li>
<li> 以日志的形式进行追加持久化</li>
<li> 日志内包含了所有的操作，便于redis的解析和恢复操作 </li>
</ul>

<h3 id="toc_6">AOF 劣势</h3>

<ul>
<li>因为是使用日志的方式，所以和RDB的快照文件相比，要大得多。</li>
<li>AOF持久化，每次写入都会有IO操作，因此频繁的IO操作，对计算机性能会有一定的消耗。</li>
<li>历史遗留的bug，AOF恢复的数据可能会有数据丢失。</li>
</ul>

<h3 id="toc_7">AOF 配置</h3>

<p>打开Redis的配置文件 redis.conf，搜索APPEND，下方的配置都是AOF配置相关的。<br/>
redis安装完毕后，默认的持久化方式是RDB模式</p>

<pre><code class="language-text"># 默认是关闭的， 启动AOF
appendonly yes

# AOF备份的文件名称
appendfilename &quot;appendonly.aof&quot;

# 同步策略
# 有写操作就同步
appendfsync always
# 每一秒
appendfsync everysec
# 关闭
appendfsync no

# 从写的时候不做写操作，否则会出现数据不一致的情况
no-appendfsync-on-rewrite no

# 重写机制，避免日志越来越大，AOF重写时，会执行flushALL命令，这个命令也会被记录到日志内，因此，在恢复的时候，需要将文件最后的flushALL命令删除，否则恢复之后是空的。
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
</code></pre>

<h2 id="toc_8">RDB 和 AOF 选择</h2>

<p>如果在可以接受在一段时间内他的缓存可以丢失的话，可以选择使用RDB模式。<br/>
如果对数据的实时性要求比较高，可以使用AOF的方式。<br/>
通常两个方法是一起使用，RDB作为冷备份，AOF用来做热备份，这样数据即使丢失最大就是在1s-2s。<br/>
redis在恢复的时候，是先去加载AOF日志进行恢复，如果AOF日志不存在，就回去使用RDB快照就恢复。这里有一个效率的问题，因为RDB是快照的方式，快照文件内记录的上一次备份时间点之前的所有数据，恢复的速度比较快，而AOF日志是记录了所有的操作命令，恢复的时候相对会比较慢，因此两个持久化的方法联合使用，不仅可以提高数据的安全性，也能提高数据恢复的速度。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[openssh-java]]></title>
    <link href="jythons.github.io/16056247075354.html"/>
    <updated>2020-11-17T22:51:47+08:00</updated>
    <id>jythons.github.io/16056247075354.html</id>
    <content type="html"><![CDATA[
<p><a href="https://github.com/apivovarov/openssh-java">https://github.com/apivovarov/openssh-java</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis发布与订阅]]></title>
    <link href="jythons.github.io/16055402422958.html"/>
    <updated>2020-11-16T23:24:02+08:00</updated>
    <id>jythons.github.io/16055402422958.html</id>
    <content type="html"><![CDATA[
<p>发布订阅，首先有一个发布者，然后有多个订阅者，每个订阅者需要去发布者那里去订阅消息，有了订阅之后，就相当于发布和订阅者之间有了一层绑定关系。当发布者发布了消息之后，所有的订阅者都可以收到这个消息。<br/>
<img src="media/16055402422958/redis%E5%8F%91%E5%B8%83%E5%92%8C%E8%AE%A2%E9%98%85.png" alt="redis发布和订阅"/></p>

<blockquote>
<p>例如：很多人关注了B站的up主，当up主发布了一条新的动态之后，所有的关注人员都会收到一条消息。这里的up主就相当于发布者，粉丝就相当于订阅者。</p>
</blockquote>

<span id="more"></span><!-- more -->

<h2 id="toc_0">redis实现发布订阅</h2>

<h3 id="toc_1">发布者</h3>

<pre><code class="language-text">publish chan message
</code></pre>

<blockquote>
<p>publish 发布消息，chan 通道，向chan通道发布消息，这里的chan和订阅者的ch是相同的，message 是发布的内容。</p>
</blockquote>

<h3 id="toc_2">订阅者</h3>

<pre><code class="language-text"># 订阅频道
subscribe ch [ch ...]
</code></pre>

<blockquote>
<p>subscribe 订阅，ch相当于频道，也就是发布者, 可以同时订阅多个频道。</p>
</blockquote>

<pre><code class="language-text"># 批量订阅，订阅所有moto开头的频道
psubscribe moto*
</code></pre>

<blockquote>
<p>redis只是实现的发布订阅的功能，生产上不建议使用redis做消息队列，专人专事，发布订阅的功能还是要使用mq去实现。</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SpringBoot整合redis]]></title>
    <link href="jythons.github.io/16055384723975.html"/>
    <updated>2020-11-16T22:54:32+08:00</updated>
    <id>jythons.github.io/16055384723975.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">添加依赖</h2>

<pre><code class="language-text">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
&lt;/dependency&gt;
</code></pre>

<span id="more"></span><!-- more -->

<h2 id="toc_1">配置yml</h2>

<pre><code class="language-text">spring:
    redis:
        database: 0
        host: 192.168.1.111
        port: 6379
        password: psword
</code></pre>

<h2 id="toc_2">使用方法</h2>

<pre><code class="language-text">@ApiIgnore
@RestController
@RequestMapping(&quot;redis&quot;)
public class RedisController {

    @Autowired
    private RedisTemplate redisTemplate

    @GetMapping(&quot;/set&quot;)
    public Object set(String key, String value) {
        redisTemplate.opsForValue().set(key, value);
        return &quot;OK&quot;;
    }
    
    @GetMapping(&quot;/get&quot;)
    public String get(String key) {
        return (String)redisTemplate.opsForValue().get (key);
    }
    
    @GetMapping(&quot;/delete&quot;)
    public Object delete(String key) {
        redisTemplate.delete(key);
        return &quot;OK&quot;;
    }
}
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis的数据类型]]></title>
    <link href="jythons.github.io/16050230410936.html"/>
    <updated>2020-11-10T23:44:01+08:00</updated>
    <id>jythons.github.io/16050230410936.html</id>
    <content type="html"><![CDATA[
<p>redis一共有五大数据类型，分别是：String、Hash、List、set、zset。下面分别介绍下每个数据类型的基本使用方法。<br/>
<a href="http://redisdoc.com">redis-doc</a></p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">String数据类型</h2>

<blockquote>
<p>keys * 查看有多少个key，使用keys命令需要慎重，他是阻塞的，因此不要在正式环境使用。</p>
</blockquote>

<pre><code class="language-text"># 查看所有的key
keys *

# 查看所有 a 开头的key
keys a*

# 查看所有以e结尾的key
keys *e

# 查询key的类型，keyname是某个key的名字
type keyname
</code></pre>

<p><strong>set：</strong> 设置一个变量，变量存在更新</p>

<blockquote>
<p>例子：set key value</p>
</blockquote>

<p><strong>setnx：</strong> 设置一个变量，变量存在，不更新，不存在则添加 </p>

<blockquote>
<p>例子：setnx key value</p>
</blockquote>

<p><strong>ttl：</strong> （time to leave）查看key剩下的时间，返回 -1，表示永久保存</p>

<blockquote>
<p>例子：ttl key</p>
</blockquote>

<p><strong>expire：</strong> 为某个key设置过期时间</p>

<blockquote>
<p>例子：expire key second</p>
</blockquote>

<p><strong>set ex：</strong> 设置带有过期时间的key</p>

<blockquote>
<p>例子：set key value ex second</p>
</blockquote>

<p><strong>append：</strong> 字符串的拼接，在现有的key字符串后拼接一个：123</p>

<blockquote>
<p>例子：append key 123</p>
</blockquote>

<p><strong>strlen：</strong> 查看字符串的长度，查看key这个字付串的长度</p>

<blockquote>
<p>例子：strlen key</p>
</blockquote>

<p><strong>incr：</strong> 累加，在当前的key对应的value数值上 +1</p>

<blockquote>
<p>例子：incr key</p>
</blockquote>

<p><strong>decr：</strong> 累减，在当前的key对应的value数值上 -1</p>

<blockquote>
<p>例子：decr key</p>
</blockquote>

<p><strong>incrby：</strong> 带有步长的累加</p>

<blockquote>
<p>例子：incrby key 步长数值，【incrby key 10】</p>
</blockquote>

<p><strong>decrby：</strong> 带有步长的累减</p>

<blockquote>
<p>例子：decrby key 步长数值，【decrby key 10】</p>
</blockquote>

<p><strong>getrange：</strong> 截取字符串的一段返回</p>

<blockquote>
<p>例子：getrange key 1 2，获取key这个字符串的第1个字符到第2个字符，从0开始算</p>
</blockquote>

<p><strong>setrange：</strong> 替换字符串的某一段</p>

<blockquote>
<p>例子：setrange key 2 aa，从第2个字符开始，替换两个字符为aa，abcde -&gt; abaae</p>
</blockquote>

<p><strong>mset：</strong> 批量设置key</p>

<blockquote>
<p>mset key value [key value ...]，mset key1 value1 key2 value2</p>
</blockquote>

<p><strong>mget：</strong> 批量获取key</p>

<blockquote>
<p>mget key [key ...]，mget key1 key2</p>
</blockquote>

<p><strong>msetnx：</strong> 设置多个key，不能设置重复的key</p>

<blockquote>
<p>msetnx key1 value1 key2 value2 , 如果当前有key1，则本命令会执行失败，key2也不会保存</p>

<p>默认情况下，redis是有16个库，默认使用的是0，可以在配置文件内修改：databases参数来设置有多少个库。使用：select num（num表示库的下标），切换不同的库。</p>
</blockquote>

<p><strong>flushdb：</strong> 清除当前库里所有的数据<br/>
<strong>flushdball：</strong> 清除所有库里的数据</p>

<blockquote>
<p>flushdb和flushdball谨慎使用</p>
</blockquote>

<h2 id="toc_1">Hash数据类型</h2>

<p>hash数据类型，可以将结构化的数据存放到内存里面去。</p>

<blockquote>
<p>记忆：hash操作的命令都是以 h 开头，后面的基本和string命令相同。</p>
</blockquote>

<h3 id="toc_2">使用方法</h3>

<p><strong>hset key field value</strong>: 添加hash类型的数据</p>

<ul>
<li>hset 表示添加一个hash数据类型的数据</li>
<li>key 数据的key</li>
<li>field 数据的字段</li>
<li>value 字段对应的值</li>
</ul>

<blockquote>
<p>例子：想要存放一个 user:{&quot;name&quot;:&quot;xiaoming&quot;, &quot;age&quot;:18, &quot;sex&quot;:&quot;man&quot;}<br/>
hset user name xiaoming<br/>
hset user age 18<br/>
hset user sex man</p>
</blockquote>

<p><strong>hget key field</strong>：获取hash类型的数据</p>

<ul>
<li>hset 表示添加一个hash数据类型的数据</li>
<li>key 数据的key</li>
<li>field 数据的字段</li>
</ul>

<blockquote>
<p>例子：获取 user:{&quot;name&quot;:&quot;xiaoming&quot;, &quot;age&quot;:18, &quot;sex&quot;:&quot;man&quot;}数据的名字<br/>
hget user name</p>
</blockquote>

<p><strong>hmset key field value [field value ...]</strong>: 为某个key批量设置字段和值</p>

<p><strong>hmget key field [field ...]</strong>: 同时获取某个key下多个字段的值</p>

<p><strong>hgetall key</strong>：获取某个key下所有的字段和值</p>

<blockquote>
<p>hgetall 的返回值是field value field value 的形式。</p>
</blockquote>

<p><strong>hlen key</strong>：返回这个key下属性的数量<br/>
<strong>hkeys key</strong>：返回key下所有的属性（field）<br/>
<strong>hvals key</strong>：返回key下所有的值（value）<br/>
<strong>hincrby key field number</strong>：key下field字段的值累加number<br/>
<strong>hincrbyfloat key field number</strong>：key下field字段的值累加number，number可以是小数<br/>
<strong>hexists key field</strong>：判断key下是否存在field属性，存在返回1<br/>
<strong>hdel key field [field ...]</strong>: 删除key的field属性，支持同时删除多个属性</p>

<h2 id="toc_3">List数据类型</h2>

<p>List 是一个列表，可以理解为数组。<br/>
List操作的命令都以 l 开头。</p>

<h3 id="toc_4">使用方法</h3>

<p><strong>lpush key value [value ...]</strong>: 从左边添加一个list数据类型的数据<br/>
<strong>lrange key start end</strong>：获取key 的数据</p>

<blockquote>
<p>例子：lrange key 0 -1 获取列表key下的所有数据</p>
</blockquote>

<p><strong>rpush key value [value ...]</strong>: 从右边添加一个list数据类型的数据<br/>
<strong>lpop key</strong>：从左边取出一个值<br/>
<strong>rpop key</strong>：从右边取出一个值<br/>
<strong>llen key</strong>：获取key的长度<br/>
<strong>lindex key num</strong>：获取key列表的下标为num的value，该方法不会删除列表的数据<br/>
<strong>lset key num value</strong>：将key列表下标为num的值修改为value<br/>
<strong>linsert key before｜after pivot value</strong>：将value插入到key列表pivot数值的前面（before）或后面（after）<br/>
<strong>lrem key count value</strong>：删除key列表内count个value<br/>
<strong>ltrim key start stop</strong>：截取key列表从start开始到stop，包含start和stop</p>

<blockquote>
<p>del key 可以删除任何数据类型的key</p>
</blockquote>

<h2 id="toc_5">Set 数据类型（集合）</h2>

<p>set数据类型，会自动删除掉重复的数据。<br/>
set数据类型的操作命令都是以 s 开头。</p>

<h3 id="toc_6">使用方法</h3>

<p><strong>sadd key member [member ...]</strong>: 添加数据<br/>
<strong>smembers key</strong>：查看key集合下所有数据<br/>
<strong>scard key</strong>：查看key集合下数据的数量<br/>
<strong>sismember key member</strong>：查看member是否在key集合下<br/>
<strong>srem key member [member ...]</strong>: 删除key集合下member，支持同时删除多个<br/>
<strong>spop key [num]</strong>: 随机获取并删除key集合下一个或多个member，num表示删除个数<br/>
<strong>srandmembe key [num]</strong>：在key集合下随机抽取一个或多个数，num表示随机抽取个数<br/>
<strong>smove source destination member</strong>：从source集合移除member并添加到destinaction集合<br/>
<strong>sdiff key [key ...]</strong>: 获取key1集合内有的，在key2内没有的数据，key1相对于key2的差集<br/>
<strong>sinter key [key ...]</strong>: 获取key1和key2集合的交集<br/>
<strong>sunion key [key ...]</strong>: 获取key1和key2集合的并集</p>

<h2 id="toc_7">Zset 数据类型（有序集合）</h2>

<p>zset和set的区别是zset每一个member都有一个分数，这个分数是有序排列的。<br/>
zset的操作命令都是以 z 开头。</p>

<h3 id="toc_8">使用方法</h3>

<p><strong>zadd key score member [score member]</strong>：有序集合添加一个key 分数为score，值为member的数据，可以添加多个。<br/>
<strong>zrange key start stop [withscores]</strong>：查询key下的数据</p>

<blockquote>
<p>例1：zrange key 0 -1 # 查看所有<br/>
例2：zrange key 0 1  # 查看下标0到1的数据<br/>
例3：zrange key 0 -1 withscores # 查看数据和分数</p>
</blockquote>

<p><strong>zrank key member</strong>：查询key下的值为member的下标</p>

<blockquote>
<p>zrank key abc 查询key下值为abc的数据在key集合的位置，这里的位置不是分数。</p>
</blockquote>

<p><strong>zscore key member</strong>：查询key集合下值为member的分数</p>

<p><strong>zcard key</strong>：查询key集合下有多少个值</p>

<p><strong>zcount key min max</strong>：查询key集合下，分数大于等于min小于等于max的值有多少个</p>

<p><strong>zrangebyscore key min max [withscores] [limit offset count]</strong>：查看分数大于等于min小于等于max的值， 加上withscores，可以展示分数</p>

<blockquote>
<p>如果查询时不想要等于边界的数据，可以使用如下方式获取：<br/>
zrangebyscore key (min (max  这样就不会包含边界值了，上面的命令也可以使用。<br/>
limit 相当于mysql的分页，limit 1 2，在结果集从第一个开始获取2个返回。</p>
</blockquote>

<p><strong>zrem key member [member]</strong>：删除key集合下值为member的数据，可删除多个</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis命令行客户端]]></title>
    <link href="jythons.github.io/16050224663931.html"/>
    <updated>2020-11-10T23:34:26+08:00</updated>
    <id>jythons.github.io/16050224663931.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">基本使用</h2>

<p>启动redis命令行客户端：</p>

<pre><code class="language-text">redis-cli
</code></pre>

<span id="more"></span><!-- more -->

<blockquote>
<p>执行set name hello，如果提示：（error）NOAUTH Authentication required，表示没有权限，需要先输入密码，执行：auth password即可（passpword是配置文件设置的密码）。</p>
</blockquote>

<p>检查redis进程是否存活：</p>

<pre><code class="language-text">redis -a password ping
</code></pre>

<p>成功会返回：PONG</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis的安装与配置]]></title>
    <link href="jythons.github.io/16049360201300.html"/>
    <updated>2020-11-09T23:33:40+08:00</updated>
    <id>jythons.github.io/16049360201300.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">Redis安装</h2>

<p><a href="https://redis.io">Redis官网</a><br/>
在官网下载redis的安装压缩包，然后解压：</p>

<pre><code class="language-text">tar -zxvf redis-6.0.9.tar.gz
cd redis-6.0.9
</code></pre>

<p>这里需要注意的是，安装redis之前需要先安装他的一个依赖：</p>

<pre><code class="language-text">yum install gcc-c++
</code></pre>

<p>然后使用 make &amp;&amp; make install 安装；</p>

<pre><code class="language-text">make &amp;&amp; make install
</code></pre>

<span id="more"></span><!-- more -->

<h2 id="toc_1">Redis配置</h2>

<p>安装好了以后，接下来需要先配置，然后才可以使用。<br/>
进入到安装目录下的 utils 文件夹：</p>

<pre><code class="language-text">cd utils
</code></pre>

<p>进去之后找到：redis_init_script文件，这个文件是redis的一个自动脚本，先复制一份：</p>

<pre><code class="language-text">cp redis_init_script /etc/init.d/
cd /etc/init.d/
</code></pre>

<p>然后再在 /usr/local/ 创建一个redis文件夹：</p>

<pre><code class="language-text">mkdir /usr/local/redis -p 
# 拷贝核心配置文件到这个目录下
cp redis.conf /usr/local/redis/
</code></pre>

<p>然后修改/usr/local/redis/这个目录下的配置文件：</p>

<pre><code class="language-text"># 找到daemonize，这个参数的意思是，redis启动后是在前台运行还是在后台运行
# yes表示在后台运行，no表示在前台运行（默认）
daemonize yes

# dir 这个参数是表示Redis的工作目录, 需要手动创建：working文件夹
dir /usr/local/redis/working

# bind 这个参数需要修改，如果不修改，只能在服务器本地使用，不能远程使用
bind 0.0.0.0

# requirepass 这个参数默认是注释掉的，表示不需要密码登录
requirepass 111111

# port 这个参数是redis启动的端口号，也可以在redis_init_script文件修改
port 6379

# pid 进程号
pid redis_6379.pid
</code></pre>

<p>配置好核心配置文件以后，接下来就要配置/etc/init.d/redis_init_script文件：</p>

<pre><code class="language-text"># 修改CONF的核心配置文件路径
CONF=&quot;/usr/local/redis/redis.conf&quot;
</code></pre>

<p>接下来就可以启动redis了</p>

<pre><code class="language-text">chmod 777 redis_init_script
# 启动
./redis_init_script start
# 停止 
./redis_init_script stop
</code></pre>

<h2 id="toc_2">配置redis开机自启动</h2>

<p>在redis_init_script文件内加上下面两段配置</p>

<pre><code class="language-text">#chkconfig：22345 10 90
#description Start and Stop redis
</code></pre>

<p>然后执行如下命令：</p>

<pre><code class="language-text">chkconfig redis_init_script on
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis简介]]></title>
    <link href="jythons.github.io/16049355266618.html"/>
    <updated>2020-11-09T23:25:26+08:00</updated>
    <id>jythons.github.io/16049355266618.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">Redis优点</h2>

<ul>
<li>丰富的数据结构</li>
<li>持久化</li>
<li>主从同步、故障转移</li>
<li>内存数据库</li>
</ul>

<h2 id="toc_1">Redis缺点</h2>

<ul>
<li>单线程</li>
<li>单核</li>
</ul>

<blockquote>
<p>redis作者认为单核单线程比较简单安全。redis不仅可以做缓存，也可以做存储，因为它支持持久化，并且数据类型更加丰富。</p>
</blockquote>

<span id="more"></span><!-- more -->

<h2 id="toc_2">与Memcache对比</h2>

<h3 id="toc_3">Memcache优点</h3>

<ul>
<li>简单的 key-value 存储</li>
<li>内存使用率比较高</li>
<li>多核处理，多线程</li>
</ul>

<h3 id="toc_4">Memcache缺点</h3>

<ul>
<li>无法容灾</li>
<li>不支持持久化</li>
</ul>

<blockquote>
<p>小数据量速度会比Memcache要快，大数据量Memcache更有优势，因为Memcache支持多核多线程处理，Redis是单核单线程的。</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[搭建Keepalived + LVS + Nginx 高可用集群负载均衡]]></title>
    <link href="jythons.github.io/16048487950121.html"/>
    <updated>2020-11-08T23:19:55+08:00</updated>
    <id>jythons.github.io/16048487950121.html</id>
    <content type="html"><![CDATA[
<p><img src="media/16048487950121/%E5%8D%95%E4%B8%AA%E5%85%A5%E5%8F%A3%E5%9B%BE%E7%89%87.png" alt="单个入口图片"/></p>

<p>当前配置的只有一个LVS负载均衡服务器，当这个服务器挂掉之后，后面所有的请求都无法到达上游RS服务器，整个服务就回挂掉，因此就需要在添加一台备用机，使用Keepalived实现主备自动切换，保证服务24小时可用。如下图所示：<br/>
<img src="media/16048487950121/%E4%B8%BB%E5%A4%87LVS%E5%88%87%E6%8D%A2.png" alt="主备LVS切换"/><br/>
使用Keepalived不但可以使LVS主备自动切换，还可以检测RS服务器是否可用，如果有挂掉的RS服务器，则会自动剔除，避免将请求转发到挂掉的RS服务器。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">在LVS服务器上配置Keepalived</h2>

<p>首先安装Keepalived，安装方法见：<a href="/16042148155872.html">Keepalived安装</a><br/>
然后编辑：keepalived.conf 配置文件</p>

<pre><code class="language-text">! 全局配置
global_defs {
   ! 路由ID：当前安装Keepalived节点主机的标识符，全局唯一
   router_id LVS_151
}

! 计算机节点，基于vrrp协议的一个实例
vrrp_instance VI_1 {
    ! 表示状态，当前服务器的nginx的主节点，MASTER/BACKUP
    state MASTER
    ! 当前实例绑定的网卡
    interface ens33
    ! 保证主备节点一致即可
    virtual_router_id 41
    ! 权重，master权重一般高于backup，如果有多个，那就是选举，谁的权重高，谁就当选
    priority 100
    ! 主备之间同步检查时间间隔，单位秒
    advert_int 1
    ! 认证权限密码。防止非法节点进入
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    
    ! 虚拟出来的ip，可以有多个（vip）
    virtual_ipaddress {
        192.168.1.150
    }
}
# 这里是LVS的配置，virtual_server是LVS服务，real_server是服务节点
virtual_server 192.168.1.150 80 {
    # 健康检查的时间，单位：秒
    delay_loop 6
    # 配置负载均衡的算法，默认是轮询，lb就是负载均衡的意思
    lb_algo rr
    # 设置LVS模式 NAT｜TUN｜DR
    lb_kind DR
    # 多少秒内多次请求转发到同一个服务器，设置会话持久化的时间
    persistence_timeout 50
    # 协议 -t
    protocol TCP

    # 负载均衡的真实服务器，也就是nginx节点的具体的真实IP地址
    real_server 192.168.1.171 80 {
        # 轮询的默认权重配比设置为1
        weight 1
        # 设置健康检查
        TCP_CHECK {
            # 检查80端口
            connect_port 80
            # 超时时间 单位：秒
            connect_timeout 2 
            # 重试次数
            nb_get_retry 2
            # 重试间隔时间，单位：秒
            delay_before_retry 3
        }
    }
    real_server 192.168.1.172 80 {
        # 轮询的默认权重配比设置为1
        weight 1
        # 设置健康检查
        TCP_CHECK {
            # 检查80端口
            connect_port 80
            # 超时时间 单位：秒
            connect_timeout 2 
            # 重试次数
            nb_get_retry 2
            # 重试间隔时间，单位：秒
            delay_before_retry 3
        }
    }
}
</code></pre>

<p>配置好以上配置后，清除ipvsadm的配置</p>

<pre><code class="language-text">ipvsadm -C
</code></pre>

<p>这样ipvs的配置就全被清除了，接下来重启Keepalived服务</p>

<pre><code class="language-text">systemctl restart keepalived
</code></pre>

<p>查看ipvs的配置是否成功：</p>

<pre><code class="language-text">ipvsadm -Ln
</code></pre>

<blockquote>
<p>如果没有输出内容，可能是keepalived的配置文件错误。<br/>
配置好MASTER之后，再将master的keepalived配置复制到backup节点配置一下，<br/>
修改router_id LVS_152, state BACKUP, priority 50, 权重官方建议和MASTER相差50即可</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[LVS的持久化机制]]></title>
    <link href="jythons.github.io/16048478935893.html"/>
    <updated>2020-11-08T23:04:53+08:00</updated>
    <id>jythons.github.io/16048478935893.html</id>
    <content type="html"><![CDATA[
<p>如果一个用户短时间内多次提交请求，那么他的请求都会转发到第一次请求的RS服务器，这个时间段默认是300秒。<br/>
配置方式：</p>

<pre><code class="language-text"># 详细信息使用：man ipvsadm
ipvsadm -E -t 192.168.1.150:80 -s rr -p [time] 
</code></pre>

<blockquote>
<p>-E 编辑服务，-t 服务地址</p>
</blockquote>

<span id="more"></span><!-- more -->

<p>通过以上配置，在访问的时候，经过time秒后，访问依然只请求到了一个服务器，这是因为有一个tcp或udp的链接超时时间，可以通过以下配置，修改超时时间。</p>

<pre><code class="language-text">ipvsadm --set 1 1 1
</code></pre>

<blockquote>
<p>ipvsadm -Lnc 查看是否有链接</p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[搭建 LVS-DR 模式]]></title>
    <link href="jythons.github.io/16043322529866.html"/>
    <updated>2020-11-02T23:50:52+08:00</updated>
    <id>jythons.github.io/16043322529866.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">服务器与 IP 约定</h2>

<p><img src="media/16043322529866/%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8EIP%E7%BA%A6%E5%AE%9A.png" alt="服务器与IP约定"/></p>

<p>首先需要有一个LVS，LVS需要有两个IP，分别是：DIP（Direct IP）和VIP (Virtual IP)；DIP就是内网IP，用于与内网上游服务器通信使用；VIP是虚拟IP，用于客户端交互使用。<br/>
然后上游服务器Nginx，Nginx服务器需要配置两个IP，分别是：RIP（Real Server IP）和VIP (Virtual IP); RIP也是内网IP，VIP也是虚拟IP，用户的请求处理完毕，通过VIP返回给客户端；Nginx服务器的VIP要和LVS的虚拟IP保持一致。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">开始搭建 LVS</h2>

<h3 id="toc_2">配置虚拟IP</h3>

<p>第一步，首先要关闭服务器网络配置管理器，如果不关闭，可能会引起接口网络的冲突，因为是在本地使用虚拟机的关系。</p>

<pre><code class="language-text"># 关闭网络配置管理器
systemctl stop NetworkManager
systemctl disable NetworkManager
</code></pre>

<p>同样 Nginx 服务器也需要关闭网络配置管理器。</p>

<p>第二步，构建LVS的IP。</p>

<pre><code class="language-text"># 进入网卡配置文件目录
cd /etc/sysconfig/network-script/
# 拷贝一份网卡配置文件，起一个别名
cp ifcfg-ens33 ifcfg-ens33:1
</code></pre>

<p>然后配置ifcfg-ens33:1文件, 配置如下：</p>

<pre><code class="language-text">BOOTPROTO=static
# 与网卡名称要保持统一
DEVICE=ens33:1
ONBOOT=yes
IPADDR=192.168.1.150
NETMASK=255.255.255.0
</code></pre>

<p>配置好网卡后，重启网卡：</p>

<pre><code class="language-text">service network restart
ip addr # 查看IP地址是否生效
</code></pre>

<p>到这里，虚拟IP就配置好了。</p>

<h3 id="toc_3">配置集群管理工具</h3>

<p>虚拟IP配置好了以后，接下来就需要配置集群管理工具。</p>

<blockquote>
<p>ipvs 是lvs自带的工具，ipvsadm需要安装。</p>
</blockquote>

<p>安装ipvsadm：</p>

<pre><code class="language-text">yum install ipvsadm
</code></pre>

<p>接下来执行如下命令查看集群列表</p>

<pre><code class="language-text">ipvsadm -Ln
</code></pre>

<blockquote>
<p>阿里云云服务器不支持虚拟IP配置，需要购买他们的负载均衡服务，腾讯云服务器支持配置虚拟IP，但是要额外的去购买的，因为是建立在网卡之上的，需要使用成本的，腾讯云支持虚拟IP的最大数量是10个。</p>
</blockquote>

<h3 id="toc_4">配置RIS节点的IP</h3>

<p>LVS服务器配置好以后，接下来去配置RIS节点服务器的IP，也就是Nginx所在的服务器。<br/>
首先也需要配置一个虚拟IP，这个IP用于返回数据报文。<br/>
首先进入到网卡配置文件所在的目录：</p>

<pre><code class="language-text"># 进入网卡配置文件目录
cd /etc/sysconfig/network-script/
</code></pre>

<p>在这个目录下，有一个 ifcfg-lo 配置文件，这个是服务器本地环回接口，我们要构建一个虚拟IP，这个IP不能被用户访问到，只是在返回报文时使用。<br/>
复制一份 ifcfg-lo 配置文件为：ifcfg-lo:1。</p>

<pre><code class="language-text">cp ifcfg-lo ifcfg-lo:1
</code></pre>

<p>修改成如下配置：</p>

<pre><code class="language-text"># BOOTPROTO=static
# 与网卡名称要保持统一
DEVICE=lo:1
ONBOOT=yes
IPADDR=192.168.1.150
NETMASK=255.255.255.255
NETWORK=127.0.0.1
BROADCAST=127.255.255.255
NAME=loopback
</code></pre>

<h3 id="toc_5">RS服务器配置ARP</h3>

<h4 id="toc_6">arp-ignore: ARP 响应级别（处理请求）</h4>

<ul>
<li>0: 只要本机配置了ip，就能响应请求（在lvs是不适用的）</li>
<li>1: 请求的目标地址到达对应的网络接口，才会响应请求（这个才是需要的）</li>
</ul>

<blockquote>
<p>配置LVS时，RS服务器需要配置一个环回地址，这个地址不能处理请求，所以要将 arp-ihnore配置成 1，请求哪个ip，哪个IP才会处理请求。</p>
</blockquote>

<h4 id="toc_7">arp-announce：ARP通告行为（返回响应）</h4>

<ul>
<li>0: 本机上任何网络接口都向外通告，所有的网卡都能接受到通告（在lvs是不适用的）</li>
<li>1: 尽可能避免本网卡与不匹配的目标进行通告（在lvs是不适用的，要一定，不能尽可能）</li>
<li>2: 只在本网卡通告（这个才是需要的） </li>
</ul>

<blockquote>
<p>RS 服务器的环回IP是用来响应客户端请求的，所以不能使用其他IP来返回，必须使用环回地址返回，因为客户端请求的是VIP，所以接收请求也必须使用RS服务器上和VIP相同的环回IP才能使客户端识别。</p>
</blockquote>

<h3 id="toc_8">配置RS服务器APR</h3>

<pre><code class="language-text"># 打开配置文件
vim /etc/sysctl.conf
# 配置如下内容：
net.ipv4.conf.all.arp_ignore = 1
net.ipv4.conf.default.arp_ignore = 1
net.ipv4.conf.lo.arp_ignore = 1
net.ipv4.conf.all.arp_announce = 2
net.ipv4.conf.default.arp_announce = 2
net.ipv4.conf.lo.arp_announce = 2
# 保存后，刷新一下网卡
sysctl -p
</code></pre>

<blockquote>
<p>all：表示所有网卡<br/>
default：表示默认网卡<br/>
lo：环回网卡</p>
</blockquote>

<h3 id="toc_9">RS 服务器配置路由</h3>

<pre><code class="language-text"># 临时配置路由，开机回失效，需要添加到开机启动配置文件内
route add -host 192.168.1.150 dev lo:1
# 永久添加, 执行如下命令
echo &quot;route add -host 192.168.1.150 dev lo:1&quot; &gt;&gt; /etc/rc.local
</code></pre>

<blockquote>
<p>通过192.168.1.150这个地址去接收请求，然后交给lo:1这个网卡去处理<br/>
使用 route -n 查看路由</p>
</blockquote>

<h3 id="toc_10">使用ipvsadm配置集群规则</h3>

<h4 id="toc_11">配置LVS服务以及节点</h4>

<pre><code class="language-text"># 添加服务
ipvsadm -A -t 192.168.1.150:80 -s rr
# 查看配置列表
ipvsadm -Ln
</code></pre>

<blockquote>
<p>添加一个服务，-A 添加一个服务，-t tcp,添加服务地址，-s 负载均衡算法，rr 轮询，轮询是负载均衡里用的比较多的算法。</p>
</blockquote>

<pre><code class="language-text"># 构建服务
ipvsadm -a -t 192.168.1.150:80 -r 192.168.1.171:80 -g
</code></pre>

<blockquote>
<p>配置服务，-a 添加一个服务节点，-t 服务地址，表示为哪个服务地址添加节点，-r real server 的意思，写RS服务器的IP地址, -g 表示是DR模式。</p>
</blockquote>

<h4 id="toc_12">验证DR模式</h4>

<pre><code class="language-text"># 查看LVS运行状态
ipvsadm -Ln
</code></pre>

<blockquote>
<p>DR 模式是LVS只负责接收请求，返回请求交给RS，通过上面的命令，查看InPkts有数据，而OutPkts为0，说明DR模式生效了。 </p>
</blockquote>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[LVS的三种模式]]></title>
    <link href="jythons.github.io/16043306453976.html"/>
    <updated>2020-11-02T23:24:05+08:00</updated>
    <id>jythons.github.io/16043306453976.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>NAT，基于网络地址转换；<br/>
TUN，基于IP隧道的模式；<br/>
DR，直接路由模式。</p>
</blockquote>

<span id="more"></span><!-- more -->

<h2 id="toc_0">LVS 模式之 NAT</h2>

<p>网络地址转换<br/>
<img src="media/16043306453976/NAT%E6%A8%A1%E5%9E%8B.png" alt="NAT模型"/></p>

<p>NAT模型和Nginx相同，LVS需要同时处理请求和返回，这样在流量比较大的情况下，会出现负载过高的问题。<br/>
NAT模型对外使用虚拟IP，与上游服务器交互使用的是私网IP，上游服务器是不能与客户端直接交互的。</p>

<h2 id="toc_1">LVS 模式之 TUN</h2>

<p>隧道模式<br/>
<img src="media/16043306453976/TUN%E6%A8%A1%E5%9E%8B.png" alt="TUN模型"/></p>

<p>TUN是基于隧道的通信方式，所有的服务器都需要通过隧道通信，使用TUN模型，所有的响应都不会经过LVS，在上游服务器处理完请求后，他会直接将响应返回给客户端，可以减轻上行请求的压力，大大提高了并发以及吞吐量。但是这个模型有一个硬性的要求，每一个服务器节点都要配备一个网卡，这样，每个服务器几点就回暴漏在公网。</p>

<h2 id="toc_2">LVS 模式之 DR</h2>

<p>直接路由模式<br/>
<img src="media/16043306453976/DR%E6%A8%A1%E5%9E%8B.png" alt="DR模型"/></p>

<p>DR模型和TUN模型相似，LVS只处理请求，响应由每个服务器节点返回，但是不同的是，服务器节点返回响应统一由路由返回，这样上游的服务器节点就不会暴漏在公网上面，大大提高的安全性。<br/>
用户通过虚拟IP访问，响应时，在路由出也构建一个虚拟IP来统一返回响应。对于用户来说，通过虚拟IP，将服务器给隐藏了起来</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[LVS简介]]></title>
    <link href="jythons.github.io/16042488055175.html"/>
    <updated>2020-11-02T00:40:05+08:00</updated>
    <id>jythons.github.io/16042488055175.html</id>
    <content type="html"><![CDATA[
<p>LVS (Linux Virtual Server)，linux虚拟服务，他是由章文嵩博士主导的开源的负载均衡项目，LVS（ipvs）被Linux系统默认集成到了Linux内核中；<br/>
LVS也是一个负载均衡调度器，是一个四层的负载均衡（Nginx是7层的负载均衡，是在内容层对请求报文的负载均衡），四层负载均衡是一个基于IP+Port的负载均衡。<br/>
<a href="http://www.linux-vs.org/index/html">官网地址</a></p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">LVS 网络拓扑图</h2>

<p><img src="media/16042488055175/%E6%88%AA%E5%B1%8F2020-11-02%20%E4%B8%8B%E5%8D%8811.06.28.png" alt="截屏2020-11-02 下午11.06.28"/></p>

<h2 id="toc_1">为什么要使用 LVS + Nginx</h2>

<ul>
<li>LVS基于四层，工作效率高，接收到请求之后可以直接转发，要比单个Nginx的性能要高几十倍</li>
<li>单个Nginx承受不了压力，需要集群</li>
<li>LVS充当Nginx集群的调度者，LVS是不会处理请求的报文的，因此承受负载的能力会更高</li>
<li>Nginx接受请求来回，LVS可以直接受不响应</li>
</ul>

<h3 id="toc_2">Nginx网络拓扑图</h3>

<p><img src="media/16042488055175/Nginx%E7%BD%91%E7%BB%9C%E6%8B%93%E6%89%91%E5%9B%BE.png" alt="Nginx网络拓扑图"/><br/>
Nginx在实现负载均衡时，需要处理请求，并处理返回结果，因此会大大增加Nginx的负载，举个例子，如果一个饭店进来吃饭和吃完饭出去的人都走同一个门，那么这个门会非常的堵。</p>

<h3 id="toc_3">LVS网络拓扑图</h3>

<p><img src="media/16042488055175/LVS%E7%BD%91%E7%BB%9C%E6%8B%93%E6%89%91%E5%9B%BE.png" alt="LVS网络拓扑图"/><br/>
LVS实现负载均衡时，LVS接受所有的请求，将请求转发给上游服务器，上游服务器处理完请求，经过LVS的某种模式，直接返回给客户端，这样大大减少了LVS的负载，并提高了整个系统的并发能力。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Keepalived 双机热备原理]]></title>
    <link href="jythons.github.io/16042463644403.html"/>
    <updated>2020-11-01T23:59:24+08:00</updated>
    <id>jythons.github.io/16042463644403.html</id>
    <content type="html"><![CDATA[
<p>双机主备的缺点：如果在主节点比较稳定，一直没有问题的话，这时备用节点的服务器一直不使用，这样会造成成本开销加大。<br/>
因此就要采用双机热备的策略，将备用节点利用起来，在没有问题时，备用节点用来做其他的事情。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">原理图</h2>

<p><img src="media/16042463644403/keeplived%E5%8F%8C%E4%B8%BB%E7%83%AD%E5%A4%87.png" alt="keeplived双主热备"/></p>

<blockquote>
<p>关于DNS轮训，可以在腾讯云或者阿里云控制台配置。</p>
</blockquote>

<h2 id="toc_1">原理</h2>

<p>当主节点没有问题时，两个节点各自维护自己的服务请求，当其中一个节点发生故障时，发生故障的节点虚拟IP会与另一个没有故障的 Nginx 绑定，将请求发送到没有故障的节点，当故障恢复后，在自动绑定回原来节点的Nginx。这里就不再区分主节点和备用节点，两个节点互为主备。</p>

<h2 id="toc_2">实现</h2>

<blockquote>
<p>规则：以一个虚拟IP分组归为同一个路由</p>
</blockquote>

<p><strong>主节点配置：</strong></p>

<pre><code class="language-text">global_defs {
    router_id keep_171
}

vrrp_script check_nginx_alive {
    script &quot;/etc/keepalived/check_nginx_alive_or_not.sh&quot;
    ! 每隔两秒运行上一行脚本
    interval 2
    ! 如果脚本运行成功，则升级权重+10
    weight 10
    ! 如果脚本运行失败，则降级权重-10
    # weight -10
}

vrrp_instance VI_1 {
    state MASTER
    interface ens33
    virtual_router_id 51
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    track_script {
        check_nginx_alive # 追踪 nginx 脚本
    }
    virtual_ipaddress {
        192.168.1.161
    }
}

vrrp_instance VI_2 {
    state BACKUP
    interface ens33
    virtual_router_id 52
    priority 80
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.1.162
    }
}
</code></pre>

<p><strong>备用节点配置：</strong></p>

<pre><code class="language-text">global_defs {
    router_id keep_171
}

vrrp_script check_nginx_alive {
    script &quot;/etc/keepalived/check_nginx_alive_or_not.sh&quot;
    ! 每隔两秒运行上一行脚本
    interval 2
    ! 如果脚本运行成功，则升级权重+10
    weight 10
    ! 如果脚本运行失败，则降级权重-10
    # weight -10
}

vrrp_instance VI_1 {
    state BACKUP
    interface ens33
    virtual_router_id 51
    priority 80
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.1.161
    }
}

vrrp_instance VI_2 {
    state MASTER
    interface ens33
    virtual_router_id 52
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    track_script {
        check_nginx_alive # 追踪 nginx 脚本
    }
    virtual_ipaddress {
        192.168.1.162
    }
}
</code></pre>

]]></content>
  </entry>
  
</feed>
