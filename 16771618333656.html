<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>  
	  
  	决策树 - 二手码农
  	
	</title>

  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

	<link href="atom.xml" rel="alternate" title="二手码农" type="application/atom+xml">

	<link href="asset/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
	<link href="asset/stylesheets/font-awesome.min.css" media="screen, projection" rel="stylesheet" type="text/css">
	<script src="asset/javascripts/jquery.min.js"></script>
	

	<!--[if lt IE 9]><script src="asset/javascripts/html5.js"></script><![endif]-->
	<!-- <link href='http://fonts.googleapis.com/css?family=Nunito:400,300,700' rel='stylesheet' type='text/css'> -->
	<style type="text/css">
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 300;
  src: local('Nunito-Light'), url(asset/font/1TiHc9yag0wq3lDO9cw0voX0hVgzZQUfRDuZrPvH3D8.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 400;
  src: local('Nunito-Regular'), url(asset/font/6TbRXKWJjpj6V2v_WyRbMX-_kf6ByYO6CLYdB4HQE-Y.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
/* latin */
@font-face {
  font-family: 'Nunito';
  font-style: normal;
  font-weight: 700;
  src: local('Nunito-Bold'), url(asset/font/TttUCfJ272GBgSKaOaD7KoX0hVgzZQUfRDuZrPvH3D8.woff2) format('woff2');
  unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2212, U+2215, U+E0FF, U+EFFD, U+F000;
}
	</style>
	
	<style type="text/css">
	.container .left-col{ opacity: 1;}
	#pagenavi a{ font-size: 1.3em;}
	#pagenavi .next:before{ top: 3px;}
	#pagenavi .prev:before{ top: 3px;}
	.container .mid-col .mid-col-container #content .archives .title{ font-size: 1.5em;}
	.container .mid-col .mid-col-container #content article{ padding: 15px 0px;}
	#header .subtitle {
		line-height: 1.2em;
		padding-top: 8px;
	}
	article pre{ background: none; border: none; padding: 0;}
	article .entry-content{text-align: left;}
	.share-comment{ padding: 25px 0px; clear: both;}
	hr{ margin: 20px 0px;border: 0; border-top:solid 1px #ddd;}
	</style>
  

</head>


<body>
	<div class="container">
		<div class="left-col">
			<div class="intrude-less">
				<header id="header" class="inner">
				 
					
					<h1><a href="index.html">二手码农</a></h1>
					<p class="subtitle">工作学习中的点点滴滴。</p>
					<nav id="main-nav">
						<ul class="main">
						
						  <li id=""><a target="_self" href="index.html">主页</a></li>
						
						  <li id=""><a target="_self" href="Java.html">Java</a></li>
						
						  <li id=""><a target="_self" href="nginx.html">Nginx</a></li>
						
						  <li id=""><a target="_self" href="Shell.html">Shell</a></li>
						
						  <li id=""><a target="_self" href="LVS.html">LVS</a></li>
						
						  <li id=""><a target="_self" href="Redis.html">Redis</a></li>
						
						  <li id=""><a target="_self" href="ES.html">ES</a></li>
						
						  <li id=""><a target="_self" href="MQ.html">MQ</a></li>
						
						  <li id=""><a target="_self" href="机器学习.html">机器学习</a></li>
						
						</ul>
					</nav>

					<nav id="sub-nav">
						<div class="social">










<a target="_blank" class="github" target="_blank" href="jythons.github.io" title="GitHub">GitHub</a>
<a target="_blank" class="email" href="mailto:jythons@sina.com" title="Email">Email</a>

								

								<a class="rss" href="atom.xml" title="RSS">RSS</a>
							
						</div>
					</nav>
				</header>				
			</div>
		</div>	
		<div class="mid-col">
			<div class="mid-col-container"> <div id="content" class="inner">

	<article class="post" itemscope itemtype="http://schema.org/BlogPosting">
		<h1 class="title" itemprop="name">决策树</h1>
		<div class="entry-content" itemprop="articleBody">
			<p>一种对实例进行<strong>分类</strong>的<strong>树形结构</strong>，通过<strong>多层判断</strong>区分目标所属类别。<br />
本质：通过多层判断，从训练数据集中归纳出一组分类规则。</p>
<span id="more"></span><!-- more -->
<h2><a id="%E4%BC%98%E7%82%B9" class="anchor" aria-hidden="true" href="#%E4%BC%98%E7%82%B9"><span class="octicon octicon-link"></span></a>优点</h2>
<ul>
<li>计算量小，运算速度快</li>
<li>易于理解，可清晰查看各属性的重要性</li>
</ul>
<h2><a id="%E7%BC%BA%E7%82%B9" class="anchor" aria-hidden="true" href="#%E7%BC%BA%E7%82%B9"><span class="octicon octicon-link"></span></a>缺点</h2>
<ul>
<li>忽略属性间的相关性</li>
<li>样本类别分布不均匀时，容易影响模型表现</li>
</ul>
<blockquote>
<p>属性间相关性是指，两个属性之间如果有关联，该模型会忽略其中的相关性。<br />
样本分布不均匀，指的是某一个样本数量比较多。</p>
</blockquote>
<h2><a id="%E5%86%B3%E7%AD%96%E6%A0%91%E6%B1%82%E8%A7%A3" class="anchor" aria-hidden="true" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E6%B1%82%E8%A7%A3"><span class="octicon octicon-link"></span></a>决策树求解</h2>
<p>假设给定训练数据集</p>
\[D = \{(x_1, y_1), (x_2, y_2),...,(x_n, y_n)\}
\]
<p>其中，</p>
\[x_i = (x_i^{(1)},x_i^{(2)},...,x_i^{(m)})^T
\]
<p>为输入实例, m为特征个数，</p>
\[y_i \in \{1,2,3,...,K\}
\]
<p>为类标记，</p>
\[i = 1,2,...,N
\]
<p>N为样本容量。</p>
<blockquote>
<p>目标：根据训练数据集构建一个<strong>决策树模型</strong>，使它能够对实例进行正确的分类。<br />
问题核心：特征选择，每一个节点，应该选用哪个特征。</p>
</blockquote>
<h3><a id="%E4%B8%89%E7%A7%8D%E6%B1%82%E8%A7%A3%E6%96%B9%E6%B3%95" class="anchor" aria-hidden="true" href="#%E4%B8%89%E7%A7%8D%E6%B1%82%E8%A7%A3%E6%96%B9%E6%B3%95"><span class="octicon octicon-link"></span></a>三种求解方法</h3>
<p>ID3、C4.5、CART</p>
<blockquote>
<p>参考资料：<br />
1.<a href="https://www.jianshu.com/p/af7fd132de30">https://www.jianshu.com/p/af7fd132de30</a><br />
2.<a href="https://www.cnblogs.com/callyblog/p/9724823.html">https://www.cnblogs.com/callyblog/p/9724823.html</a></p>
</blockquote>
<h4><a id="id3" class="anchor" aria-hidden="true" href="#id3"><span class="octicon octicon-link"></span></a>ID3</h4>
<p>利用信息熵原理选择信息增益最大的属性作为分类属性，递归的拓展决策树的分支，完成决策树的构造。<br />
信息熵（entropy）是度量随机变量不确定性的指标，熵越大，变量的不确定性就越大。假定当前样本集合D中第k类样本所占的比例为\(p_k\)，则D的信息熵为：</p>
\[Ent(D) = -\sum_{k=1}^{|y|}{p_klog_2P_k}
\]
<p>Ent(D)的值越小，变量的不确定性越小。</p>
\[p_k = 1 时：  
Ent(D) = 0
\]
<p>根据信息熵，可以计算以属性a进行样本划分带来的信息增益：</p>
\[Gain(D,a) = Ent(D) - \sum_{v=1}^V{D^v\over D}Ent(D^v)
\]
<p>V为根据属性a划分出的类别数，D为当前样本总数，\(D^v\)为类别v样本数。</p>
<p>\(Ent(D)\): 划分前的信息熵</p>
<p>\(\sum_{v=1}^V{D^v\over D}Ent(D^v)\)：划分后的信息熵</p>
<blockquote>
<p>目标：<strong>划分后样本分布不确定性尽可能小</strong>，即划分后信息熵小，信息增益大</p>
</blockquote>
<p>示例：<br />
<img src="media/16771618333656/WX20230223-230415.png" alt="WX20230223-230415" /></p>
<blockquote>
<p>选择信息增益最大的属性作为第一个节点。</p>
</blockquote>
<p>模型计算出来的结果：
<img src="media/16771618333656/WX20230223-230513.png" alt="WX20230223-230513" /></p>
<h2><a id="%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B" class="anchor" aria-hidden="true" href="#%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B"><span class="octicon octicon-link"></span></a>异常检测</h2>
<p>概念：根据输入数据，对不符合预期模式的数据进行识别。</p>
<h3><a id="%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6" class="anchor" aria-hidden="true" href="#%E6%A6%82%E7%8E%87%E5%AF%86%E5%BA%A6"><span class="octicon octicon-link"></span></a>概率密度</h3>
<p>概念：概率密度函数是一个描述随机变量在某个确定的取值点附近的可能性的函数。</p>
<h4><a id="%E5%85%AC%E5%BC%8F" class="anchor" aria-hidden="true" href="#%E5%85%AC%E5%BC%8F"><span class="octicon octicon-link"></span></a>公式</h4>
<p>区间\((x_1, x_2)\)的概率为：</p>
\[P(x_1, x_2) = \int_{x_1}^{x_2}{p(x)dx}
\]
<blockquote>
<p>\(p(x)\)是概率密度</p>
</blockquote>
<h4><a id="%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83" class="anchor" aria-hidden="true" href="#%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83"><span class="octicon octicon-link"></span></a>高斯分布</h4>
<p>高斯分布的概率密度函数是：</p>
\[p(x) = {1\over\delta\sqrt 2\pi}e^{-(x-\mu)^2\over 2\delta^2}
\]
<blockquote>
<p>其中，\(\mu\)为数据均值，\(\delta\)为标准差</p>
</blockquote>
\[\mu = {1\over m}\sum_{i=1}^mx^{(i)}
\]
\[\delta^2 = {1\over m}\sum_{i=1}^m{(x^{(i)}-\mu)^2}
\]
<p>当数据维度高于一维：</p>
\[\begin{pmatrix}
x_1^{(1)},&amp;x_1^{(2)},&amp;...&amp;x_1^{(m)}\\
x_n^{(1)},&amp;x_n^{(2)},&amp;...&amp;x_n^{(m)}\\
\end{pmatrix}
\]
<p>1、计算数据均值\(\mu_1,\mu_2,...\mu_n,\)，标准差\(\delta_1,\delta_1,...,\delta_n\)</p>
\[\mu_j = {1\over m}\sum_{i=1}^mx_j^{(i)}
\]
\[\delta_j^2 = {1\over m}\sum_{i=1}^m{(x_j^{(i)}-\mu_j)^2}
\]
<p>2、计算概率密度函数\(p(x)\):</p>
\[p(x) = \prod_{j=1}^{n}p(x_j;\mu_j,\delta_j^2) = \prod_{j=1}^{n}{1\over \delta_j\sqrt 2\pi}e^{-{(x_j-\mu_j)^2\over 2\delta_j^2}}
\]
<blockquote>
<p>判断\(p(x)\)是否大于阈值，小于阈值，标识该点为异常点。</p>
</blockquote>
<h2><a id="%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%EF%BC%88pca%EF%BC%89" class="anchor" aria-hidden="true" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%EF%BC%88pca%EF%BC%89"><span class="octicon octicon-link"></span></a>主成分分析（PCA）</h2>
<h3><a id="%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4%EF%BC%88dimensionality-reduction%EF%BC%89" class="anchor" aria-hidden="true" href="#%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4%EF%BC%88dimensionality-reduction%EF%BC%89"><span class="octicon octicon-link"></span></a>数据降维（Dimensionality Reduction）</h3>
<p>数据降维，是指在某些限定条件下，降低随机变量个数，得到一组“不相关”主变量的过程。
数据降维技术中，PCA（principal components analysis）是应用最多的方法。</p>
<h4><a id="%E4%BD%9C%E7%94%A8" class="anchor" aria-hidden="true" href="#%E4%BD%9C%E7%94%A8"><span class="octicon octicon-link"></span></a>作用</h4>
<ul>
<li>减少模型分析数据量，提升处理效率，降低计算难度；</li>
<li>实现数据可视化。</li>
</ul>
<h4><a id="pca" class="anchor" aria-hidden="true" href="#pca"><span class="octicon octicon-link"></span></a>PCA</h4>
<h5><a id="%E7%9B%AE%E6%A0%87" class="anchor" aria-hidden="true" href="#%E7%9B%AE%E6%A0%87"><span class="octicon octicon-link"></span></a>目标</h5>
<p>寻找k(k&lt;n)维新数据，使它们反映事物的主要特征。</p>
<h5><a id="%E6%A0%B8%E5%BF%83" class="anchor" aria-hidden="true" href="#%E6%A0%B8%E5%BF%83"><span class="octicon octicon-link"></span></a>核心</h5>
<p>在信息损失尽可能少的情况下，降低数据维度。</p>
<h4><a id="%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B" class="anchor" aria-hidden="true" href="#%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B"><span class="octicon octicon-link"></span></a>计算过程</h4>
<ol>
<li>原始数据预处理（标准化：\(\mu = 0, \delta=1\)）</li>
<li>计算协方差矩阵特征向量，以及数据在各特征向量投影后的方差</li>
<li>根据需求（任务指定或方差比例）确定降维维度k</li>
<li>选取k维特征向量，计算数据在其形成空间的投影</li>
</ol>
<h2><a id="iris%E6%95%B0%E6%8D%AE%E9%9B%86" class="anchor" aria-hidden="true" href="#iris%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="octicon octicon-link"></span></a>Iris数据集</h2>
<p>Iris鸢(yuan)尾花数据集是一个经典数据集，在统计学习和机器学习领域都经常被用作示例</p>
<h2><a id="%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83" class="anchor" aria-hidden="true" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="octicon octicon-link"></span></a>决策树模型训练</h2>
<pre><code class="language-python">from sklearn import tree
# 实例化一个决策树模型
dc_tree = tree.DecisionTreeClassifier(criterion='entropy', min_samples_leaf=5)
# 训练模型
dc_tree.fit(X, y)

# 可视化决策树
tree.plot_tree(dc_tree, filled='Tree',
feature_names=['SepalLength','SepalWidth','PetalLength','PetalWidth'], 
class_names=['setosa','versicolor','virginica']    
)
</code></pre>
<blockquote>
<p>criterion='entropy', 采用信息增益最大化（ID3算法），min_samples_leaf=5 表示样本数量多少就不去在分的数量</p>
</blockquote>
<h2><a id="%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83" class="anchor" aria-hidden="true" href="#%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="octicon octicon-link"></span></a>异常检测模型训练</h2>
<pre><code class="language-python">from sklearn.covariance import EllipticEnvelope
clf = EllipticEnvelope()
clf.fit(data)

# 可视化异常数据
anamoly_points = plt.scatter(
    data.loc[:, 'x1'][y_predict == -1],
    data.loc[:, 'x2'][y_predict == -1],
    marker = 'o',
    facecolor = &quot;none&quot;,
    edgecolor = &quot;red&quot;,
    s = 250
)
</code></pre>
<h2><a id="pca-iris%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4%E5%90%8E%E5%88%86%E7%B1%BB" class="anchor" aria-hidden="true" href="#pca-iris%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4%E5%90%8E%E5%88%86%E7%B1%BB"><span class="octicon octicon-link"></span></a>PCA(iris数据降维后分类)</h2>
<pre><code class="language-python"># 模型训练获得PCA降维后数据
from sklearn.decomposition import PCA
# n_components表示维度，等于4就是4维
pca = PCA(n_components=4)
X_reduced = pca.fit_transform(X_norm)
</code></pre>
<blockquote>
<p>X_norm是标准化处理之后的数据，标准化处理的方式：</p>
</blockquote>
<pre><code class="language-python">from sklearn.preprocessing import StandardScaler
X_norm = StandardScaler().fit_transform(X)
</code></pre>
<h2><a id="%E8%AE%A1%E7%AE%97%E5%90%84%E6%88%90%E5%88%86%E6%8A%95%E5%BD%B1%E6%95%B0%E6%8D%AE%E6%96%B9%E5%B7%AE%E6%AF%94%E4%BE%8B" class="anchor" aria-hidden="true" href="#%E8%AE%A1%E7%AE%97%E5%90%84%E6%88%90%E5%88%86%E6%8A%95%E5%BD%B1%E6%95%B0%E6%8D%AE%E6%96%B9%E5%B7%AE%E6%AF%94%E4%BE%8B"><span class="octicon octicon-link"></span></a>计算各成分投影数据方差比例</h2>
<pre><code class="language-python">var_ratio = pca.explained_variance_ratio_
</code></pre>
<h2><a id="%E5%8F%AF%E8%A7%86%E5%8C%96%E6%96%B9%E5%B7%AE%E6%AF%94%E4%BE%8B%EF%BC%9A" class="anchor" aria-hidden="true" href="#%E5%8F%AF%E8%A7%86%E5%8C%96%E6%96%B9%E5%B7%AE%E6%AF%94%E4%BE%8B%EF%BC%9A"><span class="octicon octicon-link"></span></a>可视化方差比例：</h2>
<pre><code class="language-python">plt.bar([1,2,3,4], var_ratio)
plt.title('variance ratio of each component')
plt.xticks([1,2,3,4], ['PC1','PC2','PC3','PC4'])
plt.ylabel('var_ratio')
plt.show()
</code></pre>
<h2><a id="%E5%8F%AF%E8%A7%86%E5%8C%96pca%E5%90%8E%E6%95%B0%E6%8D%AE%EF%BC%9A" class="anchor" aria-hidden="true" href="#%E5%8F%AF%E8%A7%86%E5%8C%96pca%E5%90%8E%E6%95%B0%E6%8D%AE%EF%BC%9A"><span class="octicon octicon-link"></span></a>可视化PCA后数据：</h2>
<pre><code class="language-python">setosa = plt.scatter(X_reduced[:,0][y==0], X_reduced[:,1][y==0])
versicolor = plt.scatter(X_reduced[:,0][y==1], X_reduced[:,1][y==1])
virginica = plt.scatter(X_reduced[:,0][y==2], X_reduced[:,1][y==2])
</code></pre>
<p>获取均值和标准差方法：<br />
均值：</p>
<pre><code class="language-python">mean = data.mean()
</code></pre>
<p>标准差：</p>
<pre><code class="language-python">sigma = data.std()
</code></pre>

		</div>
	</article>
	<div class="share-comment">
	 

	  

	  

	</div>
</div>        </div>
			<footer id="footer" class="inner">Copyright &copy; 2014
Powered by <a target="_blank" href="http://www.mweb.im">MWeb</a> &nbsp;&nbsp; 
Theme by <a href="http://shashankmehta.in/archive/2012/greyshade.html">Shashank Mehta</a>
      </footer>
		</div>
	</div>



<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: "AMS" } }});</script>

  













<script src="asset/prism.js"></script>


<style type="text/css">
figure{margin: 1em 0;padding: 0;}
  figcaption{text-align:center;}

/* PrismJS 1.14.0
https://prismjs.com/download.html#themes=prism-coy&languages=markup+css+clike+javascript */
/**
 * prism.js Coy theme for JavaScript, CoffeeScript, CSS and HTML
 * Based on https://github.com/tshedor/workshop-wp-theme (Example: http://workshop.kansan.com/category/sessions/basics or http://workshop.timshedor.com/category/sessions/basics);
 * @author Tim  Shedor
 */

code[class*="language-"],
pre[class*="language-"] {
  color: black;
  background: none;
  font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.5;

  -moz-tab-size: 4;
  -o-tab-size: 4;
  tab-size: 4;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  position: relative;
  margin: .5em 0;
  overflow: visible;
  padding: 0;
}
pre[class*="language-"]>code {
  position: relative;
  border-left: 10px solid #358ccb;
  box-shadow: -1px 0px 0px 0px #358ccb, 0px 0px 0px 1px #dfdfdf;
  background-color: #fdfdfd;
  background-image: linear-gradient(transparent 50%, rgba(69, 142, 209, 0.04) 50%);
  background-size: 3em 3em;
  background-origin: content-box;
  background-attachment: local;
}

code[class*="language"] {
  max-height: inherit;
  height: inherit;
  padding: 0 1em;
  display: block;
  overflow: auto;
}

/* Margin bottom to accomodate shadow */
:not(pre) > code[class*="language-"],
pre[class*="language-"] {
  background-color: #fdfdfd;
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
  margin-bottom: 1em;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  position: relative;
  padding: .2em;
  border-radius: 0.3em;
  color: #c92c2c;
  border: 1px solid rgba(0, 0, 0, 0.1);
  display: inline;
  white-space: normal;
}

pre[class*="language-"]:before,
pre[class*="language-"]:after {
  content: '';
  z-index: -2;
  display: block;
  position: absolute;
  bottom: 0.75em;
  left: 0.18em;
  width: 40%;
  height: 20%;
  max-height: 13em;
  box-shadow: 0px 13px 8px #979797;
  -webkit-transform: rotate(-2deg);
  -moz-transform: rotate(-2deg);
  -ms-transform: rotate(-2deg);
  -o-transform: rotate(-2deg);
  transform: rotate(-2deg);
}

:not(pre) > code[class*="language-"]:after,
pre[class*="language-"]:after {
  right: 0.75em;
  left: auto;
  -webkit-transform: rotate(2deg);
  -moz-transform: rotate(2deg);
  -ms-transform: rotate(2deg);
  -o-transform: rotate(2deg);
  transform: rotate(2deg);
}

.token.comment,
.token.block-comment,
.token.prolog,
.token.doctype,
.token.cdata {
  color: #7D8B99;
}

.token.punctuation {
  color: #5F6364;
}

.token.property,
.token.tag,
.token.boolean,
.token.number,
.token.function-name,
.token.constant,
.token.symbol,
.token.deleted {
  color: #c92c2c;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.function,
.token.builtin,
.token.inserted {
  color: #2f9c0a;
}

.token.operator,
.token.entity,
.token.url,
.token.variable {
  color: #a67f59;
  background: rgba(255, 255, 255, 0.5);
}

.token.atrule,
.token.attr-value,
.token.keyword,
.token.class-name {
  color: #1990b8;
}

.token.regex,
.token.important {
  color: #e90;
}

.language-css .token.string,
.style .token.string {
  color: #a67f59;
  background: rgba(255, 255, 255, 0.5);
}

.token.important {
  font-weight: normal;
}

.token.bold {
  font-weight: bold;
}
.token.italic {
  font-style: italic;
}

.token.entity {
  cursor: help;
}

.namespace {
  opacity: .7;
}

@media screen and (max-width: 767px) {
  pre[class*="language-"]:before,
  pre[class*="language-"]:after {
    bottom: 14px;
    box-shadow: none;
  }

}

/* Plugin styles */
.token.tab:not(:empty):before,
.token.cr:before,
.token.lf:before {
  color: #e0d7d1;
}

/* Plugin styles: Line Numbers */
pre[class*="language-"].line-numbers.line-numbers {
  padding-left: 0;
}

pre[class*="language-"].line-numbers.line-numbers code {
  padding-left: 3.8em;
}

pre[class*="language-"].line-numbers.line-numbers .line-numbers-rows {
  left: 0;
}

/* Plugin styles: Line Highlight */
pre[class*="language-"][data-line] {
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 0;
}
pre[data-line] code {
  position: relative;
  padding-left: 4em;
}
pre .line-highlight {
  margin-top: 0;
}

pre[class*="language-"].line-numbers {
    position: relative;
    padding-left: 3.8em;
    counter-reset: linenumber;
}

pre[class*="language-"].line-numbers > code {
    position: relative;
    white-space: inherit;
}

.line-numbers .line-numbers-rows {
    position: absolute;
    pointer-events: none;
    top: 0;
    font-size: 100%;
    left: -3.8em;
    width: 3em; /* works for line-numbers below 1000 lines */
    letter-spacing: -1px;
    border-right: 1px solid #999;

    -webkit-user-select: none;
    -moz-user-select: none;
    -ms-user-select: none;
    user-select: none;

}

    .line-numbers-rows > span {
        pointer-events: none;
        display: block;
        counter-increment: linenumber;
    }

        .line-numbers-rows > span:before {
            content: counter(linenumber);
            color: #999;
            display: block;
            padding-right: 0.8em;
            text-align: right;
        }

</style>
  
    


</body>
</html>